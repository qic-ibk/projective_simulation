# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/lib_nbs/02_ECMs.ipynb.

# %% auto 0
__all__ = ['standard_ps_upd', 'Abstract_ECM', 'Two_Layer', 'Priming_ECM', 'Bayesian_Network', 'Bayesian_Memory']

# %% ../nbs/lib_nbs/02_ECMs.ipynb 5
def standard_ps_upd(reward, hmatrix, gmatrix, h_damp, g_damp):
    """
    Given a reward, updates h-matrix and g-matrix following the standard PS update rule:

    h <- h - h_damp*(h-1)+ reward*g
    g <- (1-g_damp)*g    
    """
    # damping h-matrix
    hmatrix = hmatrix - h_damp*(hmatrix-1.)
    # update h-matrix
    hmatrix += reward*gmatrix
    # update g-matrix
    gmatrix = (1-g_damp)*gmatrix

    return hmatrix, gmatrix

# %% ../nbs/lib_nbs/02_ECMs.ipynb 8
from .methods.lib_helpers import CustomABCMeta
from abc import abstractmethod


class Abstract_ECM(metaclass = CustomABCMeta):
    """
    Abstract agent class any episodic and compositional memory (ECM) should be derived from. Asserts that the necessary methods are implemented.
    """

    def __init__(self):
        '''
        No restrictions on the constructor, as the ECM can be anything that has a sample module.
        '''
        pass

    @abstractmethod
    def sample(self,):
        """
        Performs a random walk through the ECM. Typically, this implies receiving an input percept and returning an action.
        """
        pass

# %% ../nbs/lib_nbs/02_ECMs.ipynb 12
import numpy as np
from .methods.transforms import _softmax

class Two_Layer(Abstract_ECM):
    def __init__(self, 
                 # The number of available actions.
                 num_actions: int, 
                 # The glow damping(or eta) parameter. 
                 g_damp: float, 
                 # The damping (or gamma) parameter. 
                 h_damp: float,
                 # If 'greedy', uses a greedy policy that samples the most action based on the h-matrix. 
                 # If 'softmax', uses a softmax policy that samples an action based on the h-matrix and a temperature parameter (encoded in policy_parameters).
                 # If object, uses this object to sample action. Input must be h_values corresponding to current percept + arbitrary policy_parameters.
                 policy: str = 'greedy',                 
                 # The parameters of the policy.
                 policy_parameters: dict = None,
                 # Method to update the g-matrix. 
                 # If 'sum', adds the new value to the current value.
                 # If 'init', sets the new value to 1.
                 glow_method: str = 'sum',
                ):

        """
        Two layer ECM. First layer, encoding the percepts observed in an environment, is initially empty (e.g. self.num_percepts = 0). As percepts
        are observed, they are added to the ECM and to the percept dictionary self.percepts. 
        The second layer, encoding the actions, has size self.num_actions.
        In practice, the ECM graph is never created. Instead, it is defined indirectly by the h-matrix and g-matrix. 
        Both have size (self.num_percepts, self.num_actions). 
        The input policy (greedy, softmax or other) is used to sample actions based on the h-matrix.

        For an end-to-end example of how to use this class, see the tutorial notebook on Basic PS agents.        
        """

        

        self.num_actions = num_actions

        self.h_damp = h_damp
        self.g_damp = g_damp
        self.glow_method = glow_method

        self.policy = policy
        self.policy_parameters = policy_parameters
        
        # Initialize ECM structures

        #int: current number of percepts.
        self.num_percepts = 0
        #np.ndarray: h-matrix with current h-values. Defaults to all 1.
        self.hmatrix = np.ones([0,self.num_actions])
        #np.ndarray: g-matrix with current glow values. Defaults to all 0.
        self.gmatrix = np.zeros([0,self.num_actions])
        #dict: Dictionary of percepts as {"percept": index}
        self.percepts = {}

    def sample(self, percept: str):
        """
        Given a percept, returns an action and changes the ECM if necessary
        First, if the percept is new, it will be added to the ECM
        Then, an action is selected as a function of the percept and the h-values of edges connected to that percept
        Finally, the g-matrix is updated based on the realized percept-action pair.
        """

        # Add percept to ECM if not already present
        self.add_percept(percept)
        # Get index from dictionary entry
        percept_index = self.percepts[percept]
        # Get h-values
        h_values = self.hmatrix[percept_index]

        # Perform Random Walk through the ECM based on h_values and current policy
        if self.policy == 'greedy': 
            # Sample greedly the action with the highest h-value
            h_values = self.hmatrix[percept_index]
            action = h_values.argmax()   

        elif self.policy == 'softmax':
            # Get probabilities from h-values through a softmax function
            prob = _softmax(self.policy_parameters, h_values)
            # Sample action based on probabilities
            action = np.random.choice(range(self.num_actions), p=prob) 

        else:
            # This considers a custom policy
            action = self.policy(h_values = h_values, **self.policy_parameters)

        # Update g-matrix
        if self.glow_method == 'sum':
            self.gmatrix[int(percept_index),int(action)] += 1.
        if self.glow_method == 'init':
            self.gmatrix[int(percept_index),int(action)] = 1.
            

        return action

    def add_percept(self, percept):
        '''
        Checks if percept is in dictionary and adds to ECM in not
        '''
        if percept not in self.percepts.keys(): 
            self.percepts[percept] = self.num_percepts
            # increment number of percepts
            self.num_percepts += 1
            # add column to h-matrix
            self.hmatrix = np.append(self.hmatrix, 
                                     np.ones([1,self.num_actions]),
                                     axis=0)
            # add column to g-matrix
            self.gmatrix = np.append(self.gmatrix, 
                                    np.zeros([1,self.num_actions]),
                                    axis=0)

    def  learn(self, reward):
        """
        Updates the h-matrix and g-matrix based on the reward received using the standard PS update rule.
        """
        self.hmatrix, self.gmatrix = standard_ps_upd(reward, self.hmatrix, self.gmatrix, self.h_damp, self.g_damp)

# %% ../nbs/lib_nbs/02_ECMs.ipynb 15
from .methods.transforms import _softmax

class Priming_ECM(Two_Layer):
    '''
    This sub-class of the Two-Layer ECM adds a variable for action priming.
    This variable should be a list of floats, each element of which corresponds to an action in the ECM.
    These "priming values" are summed with h-values of any edge connected to the associated action node prior to calculating walk probabilites with the softmax function
    '''
    def __init__(self, 
                 num_actions: int, # The number of available actions.                 
                 glow: float = 0.1, # The glow (or eta) parameter. 
                 damp: float = 0.01, # The damping (or gamma) parameter. 
                 softmax: float = 0.5, # The softmax (or beta) parameter.
                 action_primes: list = None, #weights on the probability that deliberation steps into each action. Defaults to 0 for each action 
                ):
        if action_primes is None:
            action_primes = [0.] * num_actions
        assert len(action_primes) == num_actions

        self.softmax = softmax
        super().__init__(num_actions, glow, damp, 
                         policy = None) # Here I made explicit that the policy is None, as we override the sample method
        self.action_primes = action_primes
        

    def sample(self, percept):
        '''
        Almost identical to the sample function of Two-Layer parent class, but sums h-values and action primes prior to calculating walk probabilities
        '''
        self.add_percept(percept)
        #Perform Random Walk
        # get index from dictionary entry
        percept_index = self.percepts[percept]
        # get h-values
        h_values = self.hmatrix[percept_index]
        #~~~Differences from two-layer sample function within
        assert len(h_values) == len (self.action_primes)
        # get probabilities from h-values and primes through a softmax function
        prob = _softmax(self.softmax, h_values + self.action_primes)
        #~~~~~~~
        # get action
        action = np.random.choice(range(self.num_actions), p=prob)        
        #pdate g-matrix
        self.gmatrix[int(percept_index),int(action)] = 1.
        return action

# %% ../nbs/lib_nbs/02_ECMs.ipynb 20
import numpy as np

class Bayesian_Network(Abstract_ECM):
    """
    Bayesian Network ECM implementation.
    """

    def __init__(
        self,
        Memory: np.ndarray,       # a list of np.arrays,
        Transition_array: np.ndarray,       # Transition matrix between m-level nodes.
        N_categories: list,          #number of states per percept category
        m_expectation: np.ndarray = None,  # Optional initial expectation distribution over m-nodes.
        data_log: bool = False       #stores surprise after each network excitation in a list
    ):
        super().__init__()
        if not sum(N_categories) == np.shape(Memory)[0]:
            raise ValueError("Memory must have a number of rows equal to the total number of percept category states")
        self.N_categories = N_categories
        self.num_m_nodes = np.shape(Memory)[1]              
        self.Memory = Memory
        if not np.shape(Memory)[1] == np.shape(Transition_array)[1]:
            raise ValueError("Memory and Transition must have the same number of columns (m_nodes)")
        if not np.shape(Transition_array)[0] == np.shape(Transition_array)[1]:
            raise ValueError("Transition must have the same number of columns and rows (m_nodes)")
        self.Transition_array = Transition_array

        self.surprise_data = [] if data_log else None

        # Initialize sensory and m-level excitations as empty arrays
        self.percept = np.empty(len(self.N_categories))
        self.m_excitation = np.empty(self.num_m_nodes)

        # Set the initial expectation to uniform if none is provided
        if m_expectation is None:
            self.m_expectation = np.full(self.num_m_nodes, fill_value = 1/self.num_m_nodes)
        else:
            self.m_expectation = m_expectation

        # Compute initial sensory expectation as a weighted sum over W_matrix
        self.sensory_expectation = np.dot(self.m_expectation, self.Memory.T)

        # Placeholder for current m-node activation vector
        self.m_activation = np.zeros(self.num_m_nodes)

    def excite_network(
        self,
        percept: np.ndarray  # Binary input vector representing the current percept.
    ):
        """Sets the sensory excitation equal to the percept vector and updates m_excitation accordingly."""
        # Check input shape
        if percept.shape[0] != len(self.N_categories):
            raise ValueError("Percept vector size does not match the number of perceptual categories.")
        for i in range(len(self.N_categories)):
            if not percept[i] in range(self.N_categories[i]):
                raise ValueError("The state of each percept category should be {0,...,N_i - 1}, where N_i is the number of states for that percept category")
                #using 0 for first state helps with indexing memory array
        self.percept = percept

        # compute each m_excitation as the product of each perceptual categories likelihood given that memory,
        active_percept_indices = self.get_active_percept_indices()
        category_likelihoods = self.Memory[active_percept_indices,:]
        self.m_excitation = np.prod(category_likelihoods, axis=0) #likelihood of percept given event memory by taking product of values in each column

    def activate(self):
        """Sets m_activation based on m_excitation and m_expectation."""
        # Compute the unnormalized activation (Bayesian inference numerator)
        numerator = self.m_excitation * self.m_expectation

        # Normalize to ensure it sums to one (Bayesian posterior)
        denominator = np.sum(numerator)

        if denominator != 0:
            self.m_activation = numerator / denominator
        else:
            # Avoid division by zero if all values are 0
            print("Warning: Activations sum to 0. This implies the agent believes it can not be in any known state and is likely to cause problems")
            self.m_activation = np.zeros(self.num_m_nodes)

    def set_expectations(self):
        """Set m_expectation and sensory_expectation based on activation and weight matrices."""
        
        # Normalize the Transition_matrix rows to form proper probability distributions (commented out because current encoding rules should enforce normalization, and this code is problematic.)
        row_sums = self.Transition_array.sum(axis=1, keepdims=True)
        # zero_matrix = np.zeros_like(self.Transition_array) #initilize with zeros
        # normalized_T_matrix = np.divide(self.Transition_array, row_sums, out=zero_matrix, where=row_sums != 0) #where row_sums is 0, no transition will be made and expectation will be lost
        assert(row_sum == 0 or row_sum == 1 for row_sum in row_sums)
        # Update m_expectation using the transition matrix and current activation
        self.m_expectation = np.dot(self.m_activation, self.Transition_array)

        # Update sensory_expectation using a transformed dot product with W_matrix
        self.sensory_expectation = np.dot(self.m_expectation, self.Memory.T)

    def get_surprise(self) -> float:
        """Compute the total surprise of the network."""
        # Compute the surprise of each element using the binary cross-entropy formula
        active_percept_indices = self.get_active_percept_indices()
        surprise_values = -np.log2(self.sensory_expectation[active_percept_indices])

        # Return total surprise as the sum over all sensory elements
        return np.sum(surprise_values)

    def get_active_percept_indices(self):
        x = self.percept.astype(int) + (np.cumsum([0] + self.N_categories[:-1])).astype(int) #add category state to category start index of Memory
        return x.tolist()
        
    def sample(self, percept) -> np.ndarray:
        '''given a percept, updates network states and returns a vector of sensory expectations'''
        self.excite_network(percept)
        if not self.surprise_data is None:
            self.surprise_data = self.surprise_data + [self.get_surprise()]
        self.activate()
        self.set_expectations()
                                           
        return self.sensory_expectation

# %% ../nbs/lib_nbs/02_ECMs.ipynb 25
from .methods.transforms import _logistic, _exponentiated_shift
import numpy as np

class Bayesian_Memory(Bayesian_Network):
    """
    BayesianMemory is a memory-augmented extension of the BayesianNetwork.
    It supports dynamic modification of internal weights to encode temporal traces.
    """
    def __init__(
        self,
        N_categories: list,        # Number of sensory input elements.
        num_m_nodes: int,                 # Number of memory nodes.
        Memory: np.ndarray = None,     # Optional sensory-to-memory weight matrix.
        m_expectation: np.ndarray = None, #Optional 1d array of prior expectations on memories
        Transition_array: np.ndarray = None,     # Optional memory transition matrix.
        timer: int = 0,                  # Starting memory time index.
        epistemic_uncertainty: float = 0,   # Discounts sensory evidence in state estimation.
        belief_uncertainty: float = 0,      # Prior for trace continuity.
        data_log = False,
        sensory_epsilon: float = 0.0001, #shifts sensory expectations to avoid absolutes. Should be very small
    ):
        # Default to informationless percept element probabilities if none provided
        if Memory is None:
            uniform_probabilities = np.concatenate([np.full(category_size, 1/category_size) for category_size in N_categories])
            Memory = uniform_probabilities[:, np.newaxis] * np.ones(num_m_nodes, dtype=uniform_probabilities.dtype) #set each memory node (columns) to uniform probabilities

        # Default to uniform transitions if none provided
        if Transition_array is None:
            Transition_array = np.zeros((num_m_nodes, num_m_nodes))

        super().__init__(Memory = Memory, Transition_array = Transition_array, N_categories = N_categories, m_expectation = m_expectation, data_log = data_log)

        self.timer = timer
        self.epistemic_uncertainty = epistemic_uncertainty
        self.belief_uncertainty = belief_uncertainty
        self.bias = np.zeros(self.num_m_nodes) #will be filled by belief uncertainty as memories are encoded
        self.sensory_epsilon = sensory_epsilon

    def encode_memory(self):
        """
        Modify W_matrix and C_matrix to encode the current percept into memory.
        This sets the current memory trace's excitation weights and transition weights.
        """
        # Encode current sensory excitation into Memory
        
        categorical_encoding = np.zeros(np.shape(self.Memory)[0]) #initialize with 0s
        categorical_encoding[self.get_active_percept_indices()] = 1 #set active percept states to 1
        self.Memory[:, self.timer] = categorical_encoding

        # Set transition from previous trace to current trace

        self.Transition_array[self.timer - 1, self.timer] = 1

        # Inhibit the excitation of the currently encoded trace
        self.m_excitation[self.timer] = 0
        self.bias[self.timer] = self.belief_uncertainty

    def excite_network(
        self,
        percept: np.ndarray  # each element gives the state of a perceptual category
    ):
        """
        Similar to function of same name for Bayesian_Network, exponentiated shift is applied to sensory evidence weights.
        This adds uncertainty as a function of the sensory evidence prior
        """
        if percept.shape[0] != len(self.N_categories):
            raise ValueError("Percept vector size does not match the number of perceptual categories.")
        for i in range(len(self.N_categories)):
            if not percept[i] in range(self.N_categories[i]):
                raise ValueError("The state of each percept category should be {0,...,N_i - 1}, where N_i is the number of states for that percept category")
                #using 0 for first state helps with indexing memory array
        self.percept = percept

        # compute each m_excitation as the product of each perceptual category's likelihood given that memory,
        active_percept_indices = self.get_active_percept_indices()
        category_likelihoods = self.Memory[active_percept_indices,:]
        uncertainty_adjusted_likelihoods = _exponentiated_shift(category_likelihoods, k = 0, epsilon = self.epistemic_uncertainty) #shift toward 0.5, proportional to epsilon (not exponentiated because k is 0)
        self.m_excitation = np.prod(uncertainty_adjusted_likelihoods, axis=0) #likelihood of percept given event memory by taking product of values in each column

    def activate(self):
        """Sets m_activation based on m_excitation and m_expectation."""
        # Compute the unnormalized activation (Bayesian inference numerator)
        numerator = self.m_excitation * self.m_expectation + self.bias

        # Normalize to ensure it sums to one (Bayesian posterior)
        denominator = np.sum(numerator)

        if denominator != 0:
            self.m_activation = numerator / denominator
        else:
            # Avoid division by zero if all values are 0
            print("Warning: Activations sum to 0. This implies the agent believes it can not be in any known state and is likely to cause problems")
            self.m_activation = np.zeros(self.num_m_nodes)
    
    def set_expectations(self):
        """
        Applies shifted exponential to sensory predictions, preventing 'absolute certainty'
        """
        super().set_expectations()
        self.sensory_expectation = _exponentiated_shift(x = self.sensory_expectation, k = 0, epsilon = self.sensory_epsilon)
        #Question of whether to let this be an edge case, or handle generally with the line above
    
    def sample(self, percept):
        self.excite_network(percept)
        if not self.surprise_data is None:
            self.surprise_data = self.surprise_data + [self.get_surprise()]
        self.activate()
        self.encode_memory()
        self.set_expectations()

        # Return the index of the maximum activated node (greedy policy)
        self.timer = (self.timer + 1) % self.num_m_nodes
        return self.sensory_expectation
    
