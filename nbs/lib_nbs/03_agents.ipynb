{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df201624-2dd7-4d78-8d6f-f6ce3a7f5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09044f1-de6a-478a-9fd3-a33f097d36b1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73690dc9-d872-4ede-9e16-4c924a00f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# From lib\n",
    "import projective_simulation.methods.preprocessors as preprocessors\n",
    "import projective_simulation.ECMs as ECMs\n",
    "\n",
    "# From others\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f1769-9b61-4682-b92a-a100bb2e1778",
   "metadata": {},
   "source": [
    "# Abstract Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8241b-5066-427f-9ca7-1b4ab9603b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Abstract_Agent(ABC):\n",
    "    \"\"\"\n",
    "    A minimal class every agent should fullfill, every agent should be Derived from this class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 ECM = None, #The ECM Object to use\n",
    "                 percept_processor = None, #An optional object for transforming observations prior to passing to ECM as a percept. Must have method \"preprocess\" \n",
    "                 action_processor = None #An optional object for transforming actions prior to passing to Environment as an actuator state. Must have method \"postprocess\" \n",
    "                ):\n",
    "        self.ECM = ECM\n",
    "        assert ECM is not None\n",
    "\n",
    "        self.percept_processor = percept_processor\n",
    "        if percept_processor is not None:\n",
    "            assert hasattr(percept_processor, \"preproccess\")\n",
    "\n",
    "        self.action_processor = action_processor\n",
    "        if action_processor is not None:\n",
    "            assert hassattr(action_processor, \"postprocess\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, \n",
    "               reward, #used to reinforce agent parameters based on desirable or aversive states\n",
    "               observation #data object passed from the environment/sensors\n",
    "              ):\n",
    "\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_action(self, \n",
    "                   percept #Data object to be processed by ECM. Likely a list np.array\n",
    "                  ):\n",
    "\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cdee4-0d32-4471-a98d-f27cb76fc165",
   "metadata": {},
   "source": [
    "# Basic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d086888-64e3-45a8-b18c-504da1f1ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Basic_PSAgent(Abstract_Agent):\n",
    "    def __init__(self, \n",
    "                 ECM = None, #if an ECM object is not given, a number of actions must be given with whi\n",
    "                 num_actions = None, # The number of available actions. If an ECM is not given, should be int\n",
    "                 glow: float = 0.1, # The glow (or eta) parameter. Won't be used if ECM is given\n",
    "                 damp: float = 0., # The damping (or gamma) parameter. Won't be used if ECM is given\n",
    "                 softmax: float = 0.1, # The softmax (or beta) parameter. Won't be used if ECM is given\n",
    "                 percept_processor = preprocessors.get_percept, \n",
    "                 action_processor = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Simple, projective simulation (PS) agent that uses a two-layer ECM. Percepts are added to the ECM as new obsevations are encountered\n",
    "                      \n",
    "        NOTE: This simple version misses some features such as clip deletion, emotion tags or generalization mechanisms.\n",
    "        \n",
    "        \"\"\"\n",
    "        assert isinstance(ECM, ECMs.Two_Layer) or isinstance(num_actions, int)\n",
    "        \n",
    "        if ECM is None:\n",
    "            self.ECM = ECMs.Two_Layer(num_actions, glow, damp, softmax)\n",
    "        else:\n",
    "            self.ECM = ECM\n",
    "\n",
    "        self.percept_processor = percept_processor        \n",
    "        \n",
    "        \n",
    "    def get_action(self, \n",
    "                observation: object # data object passed from the environment/sensors\n",
    "               )-> int : # The action to be performed.\n",
    "        \"\"\"\n",
    "        Given a percept, returns an action. For basic PS, these processess are mainly executed by the ECM's deliberate function\n",
    "        \"\"\"\n",
    "        percept = self.percept_processor(observation)\n",
    "        action = self.ECM.deliberate(percept)\n",
    "        return action\n",
    "\n",
    "    def update(self, \n",
    "               reward #Value used for reinforcement. Likely a float\n",
    "              ):\n",
    "        \"\"\"\n",
    "        Given a reward, updates h-matrix. Updates g-matrix with glow.\n",
    "        \"\"\"\n",
    "        self.ECM.learn(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d55a55-6ad5-4db8-b2fd-381ed3dd3d61",
   "metadata": {},
   "source": [
    "# Situated Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2cf42b-a012-4223-85ca-281278b5c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Situated_Agent(Abstract_Agent):\n",
    "    def __init__(self, \n",
    "                 reflex_ECM = None, #if an ECM object is not given, a number of actions must be given with which to create one\n",
    "                 episode_ECM = None, #if an ECM object is not given, a memory capacity must be given. This will be used to creat a new ECM\n",
    "                 num_actions = None, # The number of available actions. If an ECM is not given, should be int\n",
    "                 memory_capacity:int = None,\n",
    "                 glow: float = 0.1, # The glow (or eta) parameter. Won't be used if ECM is given\n",
    "                 damp: float = 0., # The damping (or gamma) parameter. Won't be used if ECM is given\n",
    "                 reflex_softmax: float = 0.1, # The softmax (or beta) parameter. Won't be used if ECM is given\n",
    "                 PS_softmax: float = 0.7,\n",
    "                 focus: float = 0,\n",
    "                 error_tolerance: float = 0.01,\n",
    "                 min_expectation: float = 0.01,\n",
    "                 deliberation_length: int = 1,\n",
    "                 t = 0,\n",
    "                 percept_processor = None, \n",
    "                 action_processor = None\n",
    "                ):\n",
    "        assert isinstance(reflex_ECM, ECMs.Priming_ECM) or isinstance(num_actions, int)\n",
    "        if reflex_ECM is None:\n",
    "            self.reflex_ECM = ECMs.Priming_ECM(num_actions, glow, damp, reflex_softmax)\n",
    "        else:\n",
    "            self.reflex_ECM = reflex_ECM\n",
    "\n",
    "        assert isinstance(episode_ECM, ECMs.Episodic_Memory) or isinstance(memory_capacity, int)\n",
    "        if episode_ECM is None:\n",
    "            self.episode_ECM = Episodic_Memory(num_actions = self.reflex_ECM.num_actions, \n",
    "                                               capacity = memory_capacity, \n",
    "                                               softmax = PS_softmax,\n",
    "                                               focus = focus,\n",
    "                                               error_tolerance = error_tolerance,\n",
    "                                               min_expectation = min_expectation,\n",
    "                                               deliberation_length = deliberation_length,\n",
    "                                               t = t\n",
    "                                              )\n",
    "        else:\n",
    "            self.episode_ECM = episode_ECM\n",
    "        assert self.reflex_ECM.num_actions == self.episode_ECM.num_actions\n",
    "        self.num_actions = self.reflex_ECM.num_actions\n",
    "\n",
    "        if percept_processor is None:\n",
    "            self.percept_processor = perprocessors.action_factorizor(num_actions = self.num_actions)\n",
    "        else:\n",
    "            self.percept_processor = percept_processor\n",
    "\n",
    "    def get_action(self, observation):\n",
    "        action = self.reflex_ECM.deliberate(str(observation))\n",
    "        percept = self.percept_processor.get_percept(observation, action)\n",
    "        self.episode_ECM.deliberate(percept) #runs predictions, priming actions for next step.\n",
    "        return(action)\n",
    "\n",
    "    def update(self):\n",
    "        reward = np.nanmean(self.episode_ECM.valences) - self.episode_ECM.surprise\n",
    "        self.ECM.learn(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acace569-797a-4b69-b698-403633743f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
