{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df201624-2dd7-4d78-8d6f-f6ce3a7f5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f1769-9b61-4682-b92a-a100bb2e1778",
   "metadata": {},
   "source": [
    "## Abstract Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c50f03a-a831-4e97-89b8-91496a86d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from sys import version_info\n",
    "import projective_simulation.methods.preprocessors as preprocessors\n",
    "import projective_simulation.ECMs as ECMs\n",
    "\n",
    "if version_info >= (3, 4):  # compatibility\n",
    "    from abc import ABC, abstractmethod\n",
    "    ABC = ABC\n",
    "else:\n",
    "    from abc import ABCMeta, abstractmethod\n",
    "    ABC = ABCMeta('ABC', (), {})\n",
    "\n",
    "\n",
    "class Abstract_Agent(ABC):\n",
    "    \"\"\"A minimal class every agent should fullfill, every agent should be Derived from this class\n",
    "\n",
    "    Examples:\n",
    "    >>> pass\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 ECM = None, #The ECM Object to use\n",
    "                 percept_processor = None, #An optional object for transforming observations prior to passing to ECM as a percept. Must have method \"preprocess\" \n",
    "                 action_processor = None #An optional object for transforming actions prior to passing to Environment as an actuator state. Must have method \"postprocess\" \n",
    "                ):\n",
    "        self.ECM = ECM\n",
    "        assert ECM is not None\n",
    "\n",
    "        self.percept_processor = percept_processor\n",
    "        if percept_processor is not None:\n",
    "            assert hasattr(percept_processor, \"preproccess\")\n",
    "\n",
    "        self.action_processor = action_processor\n",
    "        if action_processor is not None:\n",
    "            assert hassattr(action_processor, \"postprocess\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, \n",
    "               reward, #used to reinforce agent parameters based on desirable or aversive states\n",
    "               observation #data object passed from the environment/sensors\n",
    "              ):\n",
    "\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_action(self, \n",
    "                   percept #Data object to be processed by ECM. Likely a list np.array\n",
    "                  ):\n",
    "\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cdee4-0d32-4471-a98d-f27cb76fc165",
   "metadata": {},
   "source": [
    "## Basic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d086888-64e3-45a8-b18c-504da1f1ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Basic_PSAgent(Abstract_Agent):\n",
    "    def __init__(self, \n",
    "                 ECM = None, #if an ECM object is not given, a number of actions must be given with whi\n",
    "                 num_actions = None, # The number of available actions. If an ECM is not given, should be int\n",
    "                 glow: float = 0.1, # The glow (or eta) parameter. Won't be used if ECM is given\n",
    "                 damp: float = 0., # The damping (or gamma) parameter. Won't be used if ECM is given\n",
    "                 softmax: float = 0.1, # The softmax (or beta) parameter. Won't be used if ECM is given\n",
    "                 percept_processor = preprocessors.get_percept, \n",
    "                 action_processor = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Simple, projective simulation (PS) agent that uses a two-layer ECM. Percepts are added to the ECM as new obsevations are encountered\n",
    "                      \n",
    "        NOTE: This simple version misses some features such as clip deletion, emotion tags or generalization mechanisms.\n",
    "        \n",
    "        \"\"\"\n",
    "        assert isinstance(ECM, Two_Layer) or isinstance(num_actions, int)\n",
    "        if ECM is None:\n",
    "            self.ECM = ECMs.Two_Layer(num_actions, glow, damp, softmax)\n",
    "        else:\n",
    "            self.ECM = ECM\n",
    "\n",
    "        self.percept_processor = percept_processor        \n",
    "        \n",
    "        \n",
    "    def get_action(self, \n",
    "                observation: object # data object passed from the environment/sensors\n",
    "               )-> int : # The action to be performed.\n",
    "        \"\"\"\n",
    "        Given a percept, returns an action. For basic PS, these processess are mainly executed by the ECM's deliberate function\n",
    "        \"\"\"\n",
    "        percept = self.percept_processor(observation)\n",
    "        action = self.ECM.deliberate(percept)\n",
    "        return action\n",
    "\n",
    "    def update(self, \n",
    "               reward #Value used for reinforcement. Likely a float\n",
    "              ):\n",
    "        \"\"\"\n",
    "        Given a reward, updates h-matrix. Updates g-matrix with glow.\n",
    "        \"\"\"\n",
    "        self.ECM.learn(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d773c2a-c58d-41cf-a093-dcfaef6be27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Situated Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2cf42b-a012-4223-85ca-281278b5c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Situated_Agent(Abstract_Agent):\n",
    "    def __init__(self, \n",
    "                 reflex_ECM = None, #if an ECM object is not given, a number of actions must be given with which to create one\n",
    "                 episode_ECM = None,\n",
    "                 num_actions = None, # The number of available actions. If an ECM is not given, should be int\n",
    "                 memory_capacity:int = None,\n",
    "                 glow: float = 0.1, # The glow (or eta) parameter. Won't be used if ECM is given\n",
    "                 damp: float = 0., # The damping (or gamma) parameter. Won't be used if ECM is given\n",
    "                 reflex_softmax: float = 0.1, # The softmax (or beta) parameter. Won't be used if ECM is given\n",
    "                 PS_softmax: float = 0.7,\n",
    "                 focus: float = 0,\n",
    "                 error_tolerance: float = 0.01,\n",
    "                 min_expectation: float = 0.01,\n",
    "                 deliberation_length: int = 1,\n",
    "                 t = 0,\n",
    "                 percept_processor = None, \n",
    "                 action_processor = None\n",
    "                ):\n",
    "        assert isinstance(reflex_ECM, Priming_ECM) or isinstance(num_actions, int)\n",
    "        if reflex_ECM is None:\n",
    "            self.reflex_ECM = ECMs.Priming_ECM(num_actions, glow, damp, reflex_softmax)\n",
    "        else:\n",
    "            self.reflex_ECM = reflex_ECM\n",
    "\n",
    "        assert isinstance(episode_ECM, Episodic_Memory) or isinstance(memory_capacity, int)\n",
    "        if episode_ECM is None:\n",
    "            self.episode_ECM = Episodic_Memory(num_actions = self.reflex_ECM.num_actions, \n",
    "                                               capacity = memory_capacity, \n",
    "                                               softmax = PS_softmax,\n",
    "                                               focus = focus,\n",
    "                                               error_tolerance = error_tolerance,\n",
    "                                               min_expectation = min_expectation,\n",
    "                                               deliberation_length = deliberation_length,\n",
    "                                               t = t\n",
    "                                              )\n",
    "        else:\n",
    "            self.episode_ECM = episode_ECM\n",
    "        assert self.reflex_ECM.num_actions == self.episode_ECM.num_actions\n",
    "        self.num_actions = self.reflex_ECM.num_actions\n",
    "\n",
    "        if percept_processor is None:\n",
    "            self.percept_processor = perprocessors.action_factorizor(num_actions = self.num_actions)\n",
    "        else:\n",
    "            self.percept_processor = percept_processor\n",
    "\n",
    "    def get_action(self, observation):\n",
    "        action = self.reflex_ECM.deliberate(str(observation))\n",
    "        percept = self.percept_processor.get_percept(observation, action)\n",
    "        self.episode_ECM.deliberate(percept) #runs predictions, priming actions for next step.\n",
    "        return(action)\n",
    "\n",
    "    def update(self):\n",
    "        reward = np.nanmean(self.episode_ECM.valences) - self.episode_ECM.surprise\n",
    "        self.ECM.learn(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acace569-797a-4b69-b698-403633743f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
