{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2454d3c4",
   "metadata": {},
   "source": [
    "# ECMs\n",
    "\n",
    "This module contains different types of episodic and compositional memories (ECMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c27c4-41b7-4367-814f-1ac318d674fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ECMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71df5a",
   "metadata": {},
   "source": [
    "# ECMs constructors\n",
    "\n",
    "Here we collect different standalone functions that will help us construct different types of ECM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422ddaf",
   "metadata": {},
   "source": [
    "## ECM updaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebfd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def standard_ps_upd(reward, hmatrix, gmatrix, h_damp, g_damp):\n",
    "    \"\"\"\n",
    "    Given a reward, updates h-matrix and g-matrix following the standard PS update rule:\n",
    "\n",
    "    h <- h - h_damp*(h-1)+ reward*g\n",
    "    g <- (1-g_damp)*g    \n",
    "    \"\"\"\n",
    "    # damping h-matrix\n",
    "    hmatrix = hmatrix - h_damp*(hmatrix-1.)\n",
    "    # update h-matrix\n",
    "    hmatrix += reward*gmatrix\n",
    "    # update g-matrix\n",
    "    gmatrix = (1-g_damp)*gmatrix\n",
    "\n",
    "    return hmatrix, gmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa87bdf",
   "metadata": {},
   "source": [
    "# Pre-built ECMs\n",
    "\n",
    "Here we collect the abstract parent class that any ECM should be built upon as well as some pre-built ECM ready to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5475b4-a17f-44f1-ba9c-3ace43286a47",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "## Abstract ECM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbeb219-d8ac-427c-8d02-868a3c884b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from projective_simulation.methods.lib_helpers import CustomABCMeta\n",
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "class Abstract_ECM(metaclass = CustomABCMeta):\n",
    "    \"\"\"\n",
    "    Abstract agent class any episodic and compositional memory (ECM) should be derived from. Asserts that the necessary methods are implemented.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        No restrictions on the constructor, as the ECM can be anything that has a sample module.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample(self,):\n",
    "        \"\"\"\n",
    "        Performs a random walk through the ECM. Typically, this implies receiving an input percept and returning an action.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab47e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the expected TypeError, test passed.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "### Test ###\n",
    "\n",
    "class test_abstract(Abstract_ECM):\n",
    "\n",
    "    def __init__(self, num_actions = 2):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    # Here we do not define on purpose the sample method, to check if the abstract class raises an error when trying to instantiate it.\n",
    "    # def sample(self):\n",
    "    #     return 0\n",
    "\n",
    "try:\n",
    "    agent = test_abstract()  # This should raise a TypeError\n",
    "except TypeError:\n",
    "    print(\"Got the expected TypeError, test passed.\")\n",
    "else:\n",
    "    raise AssertionError(\"TestAgent() did NOT raise TypeError but it should have.\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93a56c-8778-4f41-93c7-6e917f669250",
   "metadata": {},
   "source": [
    "## Two Layer ECMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97738bf4-5dc1-4b6d-b893-c9057675e02f",
   "metadata": {},
   "source": [
    "### Basic Two Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96b30c-66ed-448a-806d-64978cab7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from projective_simulation.methods.transforms import _softmax\n",
    "\n",
    "class Two_Layer(Abstract_ECM):\n",
    "    def __init__(self, \n",
    "                 # The number of available actions.\n",
    "                 num_actions: int, \n",
    "                 # The glow damping(or eta) parameter. \n",
    "                 g_damp: float, \n",
    "                 # The damping (or gamma) parameter. \n",
    "                 h_damp: float,\n",
    "                 # If 'greedy', uses a greedy policy that samples the most action based on the h-matrix. \n",
    "                 # If 'softmax', uses a softmax policy that samples an action based on the h-matrix and a temperature parameter (encoded in policy_parameters).\n",
    "                 # If object, uses this object to sample action. Input must be h_values corresponding to current percept + arbitrary policy_parameters.\n",
    "                 policy: str = 'greedy',                 \n",
    "                 # The parameters of the policy.\n",
    "                 policy_parameters: dict = None,\n",
    "                 # Method to update the g-matrix. \n",
    "                 # If 'sum', adds the new value to the current value.\n",
    "                 # If 'init', sets the new value to 1.\n",
    "                 glow_method: str = 'sum',\n",
    "                ):\n",
    "\n",
    "        \"\"\"\n",
    "        Two layer ECM. First layer, encoding the percepts observed in an environment, is initially empty (e.g. self.num_percepts = 0). As percepts\n",
    "        are observed, they are added to the ECM and to the percept dictionary self.percepts. \n",
    "        The second layer, encoding the actions, has size self.num_actions.\n",
    "        In practice, the ECM graph is never created. Instead, it is defined indirectly by the h-matrix and g-matrix. \n",
    "        Both have size (self.num_percepts, self.num_actions). \n",
    "        The input policy (greedy, softmax or other) is used to sample actions based on the h-matrix.\n",
    "\n",
    "        For an end-to-end example of how to use this class, see the tutorial notebook on Basic PS agents.        \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.h_damp = h_damp\n",
    "        self.g_damp = g_damp\n",
    "        self.glow_method = glow_method\n",
    "\n",
    "        self.policy = policy\n",
    "        self.policy_parameters = policy_parameters\n",
    "        \n",
    "        # Initialize ECM structures\n",
    "\n",
    "        #int: current number of percepts.\n",
    "        self.num_percepts = 0\n",
    "        #np.ndarray: h-matrix with current h-values. Defaults to all 1.\n",
    "        self.hmatrix = np.ones([0,self.num_actions])\n",
    "        #np.ndarray: g-matrix with current glow values. Defaults to all 0.\n",
    "        self.gmatrix = np.zeros([0,self.num_actions])\n",
    "        #dict: Dictionary of percepts as {\"percept\": index}\n",
    "        self.percepts = {}\n",
    "\n",
    "    def sample(self, percept: str):\n",
    "        \"\"\"\n",
    "        Given a percept, returns an action and changes the ECM if necessary\n",
    "        First, if the percept is new, it will be added to the ECM\n",
    "        Then, an action is selected as a function of the percept and the h-values of edges connected to that percept\n",
    "        Finally, the g-matrix is updated based on the realized percept-action pair.\n",
    "        \"\"\"\n",
    "\n",
    "        # Add percept to ECM if not already present\n",
    "        self.add_percept(percept)\n",
    "        # Get index from dictionary entry\n",
    "        percept_index = self.percepts[percept]\n",
    "        # Get h-values\n",
    "        h_values = self.hmatrix[percept_index]\n",
    "\n",
    "        # Perform Random Walk through the ECM based on h_values and current policy\n",
    "        if self.policy == 'greedy': \n",
    "            # Sample greedly the action with the highest h-value\n",
    "            h_values = self.hmatrix[percept_index]\n",
    "            action = h_values.argmax()   \n",
    "\n",
    "        elif self.policy == 'softmax':\n",
    "            # Get probabilities from h-values through a softmax function\n",
    "            prob = _softmax(self.policy_parameters, h_values)\n",
    "            # Sample action based on probabilities\n",
    "            action = np.random.choice(range(self.num_actions), p=prob) \n",
    "\n",
    "        else:\n",
    "            # This considers a custom policy\n",
    "            action = self.policy(h_values = h_values, **self.policy_parameters)\n",
    "\n",
    "        # Update g-matrix\n",
    "        if self.glow_method == 'sum':\n",
    "            self.gmatrix[int(percept_index),int(action)] += 1.\n",
    "        if self.glow_method == 'init':\n",
    "            self.gmatrix[int(percept_index),int(action)] = 1.\n",
    "            \n",
    "\n",
    "        return action\n",
    "\n",
    "    def add_percept(self, percept):\n",
    "        '''\n",
    "        Checks if percept is in dictionary and adds to ECM in not\n",
    "        '''\n",
    "        if percept not in self.percepts.keys(): \n",
    "            self.percepts[percept] = self.num_percepts\n",
    "            # increment number of percepts\n",
    "            self.num_percepts += 1\n",
    "            # add column to h-matrix\n",
    "            self.hmatrix = np.append(self.hmatrix, \n",
    "                                     np.ones([1,self.num_actions]),\n",
    "                                     axis=0)\n",
    "            # add column to g-matrix\n",
    "            self.gmatrix = np.append(self.gmatrix, \n",
    "                                    np.zeros([1,self.num_actions]),\n",
    "                                    axis=0)\n",
    "\n",
    "    def  learn(self, reward):\n",
    "        \"\"\"\n",
    "        Updates the h-matrix and g-matrix based on the reward received using the standard PS update rule.\n",
    "        \"\"\"\n",
    "        self.hmatrix, self.gmatrix = standard_ps_upd(reward, self.hmatrix, self.gmatrix, self.h_damp, self.g_damp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d52db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "### Test ###\n",
    "\n",
    "# Greedy policy\n",
    "ECM_2l_greedy = Two_Layer(4,1,1)\n",
    "ECM_2l_greedy.sample(0)\n",
    "\n",
    "# Softmax policy\n",
    "ECM_2l_softmax = Two_Layer(4,1,1, policy = 'softmax', policy_parameters = 1)\n",
    "ECM_2l_softmax.sample(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f161bf-f152-47b7-a791-bcbcf5f8af3d",
   "metadata": {},
   "source": [
    "### Priming Two Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca43ac0-7080-4f63-9418-0bf032ce8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from projective_simulation.methods import transforms\n",
    "\n",
    "class Priming_ECM(Two_Layer):\n",
    "    '''\n",
    "    This sub-class of the Two-Layer ECM adds a variable for action priming.\n",
    "    This variable should be a list of floats, each element of which corresponds to an action in the ECM.\n",
    "    These \"priming values\" are summed with h-values of any edge connected to the associated action node prior to calculating walk probabilites with the softmax function\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 num_actions: int, # The number of available actions.                 \n",
    "                 glow: float = 0.1, # The glow (or eta) parameter. \n",
    "                 damp: float = 0.01, # The damping (or gamma) parameter. \n",
    "                 softmax: float = 0.5, # The softmax (or beta) parameter.\n",
    "                 action_primes: list = None, #weights on the probability that deliberation steps into each action. Defaults to 0 for each action \n",
    "                ):\n",
    "        if action_primes is None:\n",
    "            action_primes = [0.] * num_actions\n",
    "        assert len(action_primes) == num_actions\n",
    "\n",
    "        self.softmax = softmax\n",
    "        super().__init__(num_actions, glow, damp, \n",
    "                         policy = None) # Here I made explicit that the policy is None, as we override the sample method\n",
    "        self.action_primes = action_primes\n",
    "        \n",
    "\n",
    "    def sample(self, percept):\n",
    "        '''\n",
    "        Almost identical to the sample function of Two-Layer parent class, but sums h-values and action primes prior to calculating walk probabilities\n",
    "        '''\n",
    "        self.add_percept(percept)\n",
    "        #Perform Random Walk\n",
    "        # get index from dictionary entry\n",
    "        percept_index = self.percepts[percept]\n",
    "        # get h-values\n",
    "        h_values = self.hmatrix[percept_index]\n",
    "        #~~~Differences from two-layer sample function within\n",
    "        assert len(h_values) == len (self.action_primes)\n",
    "        # get probabilities from h-values and primes through a softmax function\n",
    "        prob = transforms._softmax(self.softmax, h_values + self.action_primes)\n",
    "        #~~~~~~~\n",
    "        # get action\n",
    "        action = np.random.choice(range(self.num_actions), p=prob)        \n",
    "        #pdate g-matrix\n",
    "        self.gmatrix[int(percept_index),int(action)] = 1.\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5f245-9469-46d2-9163-77933555e13d",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3660f-8cbd-4852-bde9-d5adb33ef485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from projective_simulation.environments import RLGL\n",
    "from projective_simulation.ECMs import Priming_ECM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b54c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ECM = Priming_ECM(num_actions = 2, action_primes = [0., 1.5])\n",
    "#Number of steps to run simulation\n",
    "T = 100\n",
    "data_log = [None] * T\n",
    "env = RLGL() #create a default red-light-green-light environment\n",
    "\n",
    "for t in range(T):\n",
    "    observation = env.get_observation()\n",
    "    action = test_ECM.sample(observation)\n",
    "    reward = env.get_reward(action)\n",
    "    test_ECM.learn(reward)\n",
    "    data_log[t] = {\"env_state\": env.state, \"action\": action, \"reward\": reward}\n",
    "    env.transition(action)\n",
    "\n",
    "plt.plot(range(T), [np.mean([data_log[step][\"reward\"] for step in range(i-10,i+1) if step >= 0]) for i in range(T)]) #plot a 10 step moving average of the reward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22153789-fe33-4262-8f6d-1dd45d28ecbf",
   "metadata": {},
   "source": [
    "## Situated Projective Simulation\n",
    "\n",
    "### Predictive Bayesian Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d57025-6adc-4a5a-bafa-d0c9d6c67ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "\n",
    "class Bayesian_Network(Abstract_ECM):\n",
    "    \"\"\"\n",
    "    Bayesian Network ECM implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        W: list,       # a list of np.arrays,\n",
    "        C_matrix: np.ndarray,       # Transition matrix between m-level nodes.\n",
    "        m_expectation: np.ndarray = None,  # Optional initial expectation distribution over m-nodes.\n",
    "        data_log: bool = False       #stores surprise after each network excitation in a list\n",
    "    ):\n",
    "        super().__init__()       \n",
    "        self.percept_category_sizes = [np.shape(W_matrix)[0] for W_matrix in W]\n",
    "        self.num_m_nodes = np.shape(C_matrix)[1]              \n",
    "        self.W = W\n",
    "        for W_matrix in W:\n",
    "            if not np.shape(W_matrix)[1] == np.shape(C_matrix)[1]:\n",
    "                raise ValueError(\"W_matrices and C_matrix must have the same number of columns (m_nodes)\")\n",
    "        if not np.shape(C_matrix)[0] == np.shape(C_matrix)[1]:\n",
    "            raise ValueError(\"C_matrix must have the same number of columns and rows (m_nodes)\")\n",
    "        self.C_matrix = C_matrix\n",
    "\n",
    "        self.surprise_data = [] if data_log else None\n",
    "\n",
    "        # Initialize sensory and m-level excitations as empty arrays\n",
    "        self.percept = np.empty(len(self.percept_category_sizes))\n",
    "        self.m_excitation = np.empty(self.num_m_nodes)\n",
    "\n",
    "        # Set the initial expectation to uniform if none is provided\n",
    "        self.m_expectation = np.full(self.num_m_nodes, fill_value=1/self.num_m_nodes) if m_expectation is None else m_expectation\n",
    "\n",
    "        # Compute initial sensory expectation as a weighted sum over W_matrix\n",
    "        self.sensory_expectation =   [np.dot(self.m_expectation, W_matrix.T) for W_matrix in self.W]\n",
    "\n",
    "        # Placeholder for current m-node activation vector\n",
    "        self.m_activation = np.zeros(self.num_m_nodes)\n",
    "\n",
    "    def excite_network(\n",
    "        self,\n",
    "        percept: np.ndarray  # Binary input vector representing the current percept.\n",
    "    ):\n",
    "        \"\"\"Sets the sensory excitation equal to the percept vector and updates m_excitation accordingly.\"\"\"\n",
    "        # Check input shape\n",
    "        if percept.shape[0] != self.num_sensory_elements:\n",
    "            raise ValueError(\"Percept vector size does not match the number of sensory elements.\")\n",
    "\n",
    "        self.percept = percept\n",
    "\n",
    "        # compute each m_excitation as the product of each sensory element's excitation likelihood,\n",
    "        categorical_likelihoods = np.vstack([W_matrix[category_state] for W_matrix, category_state in zip(self.W, self.percept)]) #likilihood of percept categories (rows) given memory (columns)\n",
    "        self.m_excitation = np.prod(categorical_likelihoods, axis=0) #likelihood of percept given memory by taking product of values in each column\n",
    "\n",
    "    def activate(self):\n",
    "        \"\"\"Sets m_activation based on m_excitation and m_expectation.\"\"\"\n",
    "        # Compute the unnormalized activation (Bayesian inference numerator)\n",
    "        numerator = self.m_excitation * self.m_expectation\n",
    "\n",
    "        # Normalize to ensure it sums to one (Bayesian posterior)\n",
    "        denominator = np.sum(numerator)\n",
    "\n",
    "        if denominator != 0:\n",
    "            self.m_activation = numerator / denominator\n",
    "        else:\n",
    "            # Avoid division by zero if all values are 0\n",
    "            print(\"Warning: Activations sum to 0. This implies the agent believes it can not be in any known state and is likely to cause problems\")\n",
    "            self.m_activation = np.zeros(self.num_m_nodes)\n",
    "\n",
    "    def set_expectations(self):\n",
    "        \"\"\"Set m_expectation and sensory_expectation based on activation and weight matrices.\"\"\"\n",
    "        \n",
    "        # Normalize the C_matrix rows to form proper probability distributions\n",
    "        row_sums = self.C_matrix.sum(axis=1, keepdims=True)\n",
    "        normalized_C_matrix = np.divide(self.C_matrix, row_sums, where=row_sums != 0)\n",
    "\n",
    "        # Update m_expectation using the transition matrix and current activation\n",
    "        self.m_expectation = np.dot(self.m_activation, normalized_C_matrix)\n",
    "\n",
    "        # Update sensory_expectation using a transformed dot product with W_matrix\n",
    "        self.sensory_expectation = [np.dot(self.m_expectation, W_matrix.T) for W_matrix in self.W]\n",
    "\n",
    "    def get_surprise(self) -> float:\n",
    "        \"\"\"Compute the total surprise of the network.\"\"\"\n",
    "        # Compute the surprise of each element using the binary cross-entropy formula\n",
    "        percept_probs = [self.sensory_expectations[k][self.percept[k]] for k in range(len(self.percept_category_size))]\n",
    "        surprise_values = -np.log2(percept_probs)\n",
    "\n",
    "        # Return total surprise as the sum over all sensory elements\n",
    "        return np.sum(surprise_values)\n",
    "\n",
    "    def sample(self, percept) -> np.ndarray:\n",
    "        '''given a percept, updates network states and returns a vector of sensory expectations'''\n",
    "        self.excite_network(percept)\n",
    "        if not self.surprise_data is None:\n",
    "            self.surprise_data = self.surprise_data + [self.get_surprise()]\n",
    "        self.activate()\n",
    "        self.set_expectations()\n",
    "                                           \n",
    "        return self.sensory_expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe612a25-6a5b-4ff3-a770-3e58ce0453a8",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "In this example, we set up an environment that alternates between flipping a pair of biased coins and a pair of fair coins. The Bayesian Network's W-matrix gives it the probabilities of the coin flips in each state, and the C-matrix gives it the alternating state sequence pattern. The network does not know which state the system starts in, however. By recording and plotting the predictions the Bayesian Network, we can see how accumulating sensory evidence over times allows the Bayesian Network to establish which state the system is in and make accurate state-based predictions about the next flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14f93a-ffed-4081-b5d9-172be494c2f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Create variable for storing prediction data an initialize bayesian network instance\u001b[39;00m\n\u001b[0;32m      8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((T,np\u001b[38;5;241m.\u001b[39mshape(W_matrix)[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;66;03m#time steps by number of sensory elements\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m test_bayesian_net \u001b[38;5;241m=\u001b[39m Bayesian_Network(W_matrix, C_matrix)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m#biased state first\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\alexa\\documents\\ps_dev\\projective_simulation\\methods\\lib_helpers.py:21\u001b[0m, in \u001b[0;36mCustomABCMeta.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot instantiate class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause it is missing method(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease implement all abstract methods (see documentation of class for details).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Otherwise, call the normal __call__ to instantiate\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m, in \u001b[0;36mBayesian_Network.__init__\u001b[1;34m(self, W, C_matrix, m_expectation, data_log)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m W\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m W_matrix \u001b[38;5;129;01min\u001b[39;00m W:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(W_matrix)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(C_matrix)[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW_matrices and C_matrix must have the same number of columns (m_nodes)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(C_matrix)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(C_matrix)[\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#Set up Paramters \n",
    "T = 100 \n",
    "W_matrix = np.array(([0.6,0.5],   #frist coin probabilities in biased and fair states\n",
    "                     [0.4,0.5]))  #second coin probabilities in biased and fair states\n",
    "C_matrix = np.array(([0,1],[1,0])) #state transition probabilities\n",
    "\n",
    "#Create variable for storing prediction data an initialize bayesian network instance\n",
    "predictions = np.zeros((T,np.shape(W_matrix)[0])) #time steps by number of sensory elements\n",
    "test_bayesian_net = Bayesian_Network(W_matrix, C_matrix)\n",
    "    \n",
    "for t in range(T):\n",
    "    if t % 2 == 0: #biased state first\n",
    "        percept = np.random.binomial(n = 1, p = W_matrix[:,0])\n",
    "    else:          #fair state second\n",
    "        percept = np.random.binomial(n = 1, p = W_matrix[:,1])\n",
    "    \n",
    "    predictions[t,:] = test_bayesian_net.sample(percept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0713a-eb09-4aab-b570-7a9c6c6819f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the predicted probabilities over time\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(T), predictions[:,0], label='Coin 1', linewidth=2, color='deepskyblue')\n",
    "plt.plot(range(T), predictions[:,1], label='Coin 2', linewidth=2, color='darkblue')\n",
    "\n",
    "plt.xlabel(\"Time (T)\")\n",
    "plt.ylabel(\"Predicted Probability (Heads)\")\n",
    "plt.title(\"Network Predictions - Alternating Bias Environment\")\n",
    "plt.legend(loc = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a5696-1060-4c4c-9d55-bb39afc26907",
   "metadata": {},
   "source": [
    "### Bayesian Memory Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55a333-2b44-406e-90b8-68a1a3bc9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from projective_simulation.methods.transforms import _logistic, _shifted_exponent\n",
    "import numpy as np\n",
    "\n",
    "class Bayesian_Memory(Bayesian_Network):\n",
    "    \"\"\"\n",
    "    BayesianMemory is a memory-augmented extension of the BayesianNetwork.\n",
    "    It supports dynamic modification of internal weights to encode temporal traces.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_sensory_elements: int,        # Number of sensory input elements.\n",
    "        num_m_nodes: int,                 # Number of memory nodes.\n",
    "        W_matrix: np.ndarray = None,     # Optional sensory-to-memory weight matrix.\n",
    "        C_matrix: np.ndarray = None,     # Optional memory transition matrix.\n",
    "        timer: int = 0,                  # Starting memory time index.\n",
    "        sensory_evidence_prior: float = 1,  # Strength of sensory evidence.\n",
    "        continuity_prior: float = 0.95,      # Prior for trace continuity.\n",
    "        data_log = False,\n",
    "        sensory_epsilon: float = 0.0001, #shifts sensory expectations to avoid absolutes. Should be very small\n",
    "    ):\n",
    "        # Default to informationless sensory weights if none provided\n",
    "        if W_matrix is None:\n",
    "            W_matrix = np.full((num_sensory_elements, num_m_nodes), fill_value=0.5)\n",
    "\n",
    "        # Default to uniform transitions if none provided\n",
    "        if C_matrix is None:\n",
    "            C_matrix = np.zeros((num_m_nodes, num_m_nodes))\n",
    "\n",
    "        super().__init__(W_matrix = W_matrix, C_matrix = C_matrix, data_log = data_log)\n",
    "\n",
    "        self.timer = timer\n",
    "        self.sensory_evidence_prior = sensory_evidence_prior\n",
    "        self.continuity_prior = continuity_prior\n",
    "        self.sensory_epsilon = sensory_epsilon\n",
    "\n",
    "    def encode_memory(self):\n",
    "        \"\"\"\n",
    "        Modify W_matrix and C_matrix to encode the current percept into memory.\n",
    "        This sets the current memory trace's excitation weights and transition weights.\n",
    "        \"\"\"\n",
    "        # Encode current sensory excitation into the W_matrix at this memory step\n",
    "        self.W_matrix[:, self.timer] = self.sensory_excitation\n",
    "\n",
    "        # Set C_matrix column for this trace with uniform transition probability\n",
    "        self.C_matrix[:, self.timer] = (1 - self.continuity_prior) / (self.num_m_nodes - 1)\n",
    "\n",
    "        # Enhance the transition from previous step to this one\n",
    "        if self.timer > 0:\n",
    "            self.C_matrix[self.timer - 1, self.timer] = self.continuity_prior\n",
    "\n",
    "        # Inhibit the excitation of the currently encoded trace\n",
    "        self.m_excitation[self.timer] = 0\n",
    "\n",
    "    def excite_network(\n",
    "        self,\n",
    "        percept: np.ndarray  # Binary input vector representing the current percept.\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Similar to function of same name for Bayesian_Network, except logistic transformation is applied to sensory evidence weights.\n",
    "        This adds uncertainty as a function of the sensory evidence prior\n",
    "        \"\"\"\n",
    "        # Check for dimensional mismatch\n",
    "        if percept.shape[0] != self.num_sensory_elements:\n",
    "            raise ValueError(\"Percept vector size does not match the number of sensory elements.\")\n",
    "\n",
    "        # Store percept as current sensory excitation\n",
    "        self.sensory_excitation = percept\n",
    "\n",
    "        # Apply logistic transformation to add uncertaint to sensory evidence\n",
    "        weighted_evidence = _logistic(self.W_matrix, x_shift=0.5, k=self.sensory_evidence_prior)\n",
    "\n",
    "        # Compute m-level excitation using product of evidence probabilities\n",
    "        self.m_excitation = np.prod(\n",
    "            np.power(weighted_evidence, self.sensory_excitation[:, np.newaxis]) *\n",
    "            np.power(1 - weighted_evidence, (1 - self.sensory_excitation)[:, np.newaxis]),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "    def set_expectations(self):\n",
    "        \"\"\"\n",
    "        Applies shifted exponential to sensory predictions, preventing 'absolute certainty'\n",
    "        \"\"\"\n",
    "        super().set_expectations()\n",
    "        self.sensory_expectation = _shifted_exponent(x = self.sensory_expectation, k = 0, epsilon = self.sensory_epsilon)\n",
    "\n",
    "    def sample(self, percept):\n",
    "        self.excite_network(percept)\n",
    "        if not self.surprise_data is None:\n",
    "            self.surprise_data = self.surprise_data + [self.get_surprise()]\n",
    "        self.encode_memory()\n",
    "        self.activate()\n",
    "        self.set_expectations()\n",
    "\n",
    "        # Return the index of the maximum activated node (greedy policy)\n",
    "        self.timer = (self.timer + 1) % self.num_m_nodes\n",
    "        return self.sensory_expectation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93399d5-3c07-45da-92e5-f6684a00556e",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "In this example, we set up an environment that alternates between flipping a pair of biased coins and a pair of fair coins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bdc14c-bec2-4fa2-aa69-434c13ebbbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Paramters \n",
    "T = 200\n",
    "flip_probs = np.array(([0.8,0.5],   #first coin probabilities in biased and fair states\n",
    "                     [0.2,0.5]))  #second coin probabilities in biased and fair states\n",
    "\n",
    "num_sensors = flip_probs.shape[0]\n",
    "num_traces = 100\n",
    "#Create variable for storing prediction data an initialize bayesian network instance\n",
    "predictions = np.zeros((T,num_sensors)) #time steps by number of sensory elements\n",
    "test_bayesian_memory = Bayesian_Memory(num_sensory_elements = num_sensors, \n",
    "                                       num_m_nodes = num_traces,\n",
    "                                       sensory_evidence_prior = 0.4,\n",
    "                                       continuity_prior = 0.98\n",
    "                                      )\n",
    "    \n",
    "for t in range(T):\n",
    "    if t % 2 == 0: #biased state first\n",
    "        percept = np.random.binomial(n = 1, p = flip_probs[:,0])\n",
    "    else:          #fair state second\n",
    "        percept = np.random.binomial(n = 1, p = flip_probs[:,1])\n",
    "    \n",
    "    predictions[t,:] = test_bayesian_memory.sample(percept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61be58-1409-4fe2-981e-d5405511ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the predicted probabilities over time\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(T), predictions[:,0], label='Coin 1', linewidth=2, color='deepskyblue')\n",
    "plt.plot(range(T), predictions[:,1], label='Coin 2', linewidth=2, color='darkblue')\n",
    "\n",
    "plt.xlabel(\"Time (T)\")\n",
    "plt.ylabel(\"Predicted Probability (Heads)\")\n",
    "plt.title(\"Network Predictions - Alternating Bias Environment\")\n",
    "plt.legend(loc = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfdddd",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# nbdev export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
