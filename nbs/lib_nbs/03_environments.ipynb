{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b6596b-bec3-426d-a1f7-a19307ea6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e3fe2-a50c-484a-b531-253024bf4940",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a72016-f636-4b71-93aa-2ec6e0a43efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133dfe8-d868-4dc5-a2df-bdb1914ab1c7",
   "metadata": {},
   "source": [
    "# Abstract Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db14b271-d931-4907-a605-7f009d2956de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Abstract_Env(ABC):\n",
    "    \"\"\"A minimal Environment, every environment should be Derived from this class.\n",
    "\n",
    "    Examples:\n",
    "    >>> pass\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 state: object):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state: an object that defines the state of the environment            \n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "\n",
    "    @abstractmethod\n",
    "    def transition(self, action):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            action: an action (or actions) to process\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_observation(self):\n",
    "        \"\"\"\n",
    "        should determine and return an observation for an agent or agents as a function of self.state\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486754ff-e1ce-4846-b83f-11ce8bcf034c",
   "metadata": {},
   "source": [
    "# Cyclic Environment\n",
    "\n",
    "This envirnoment defines a fixed sequence of percepts that may be passed to an agent. Primarily useful for testing predictive ECMs in Hidden Markov Processes with no observation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba9191cc-4621-474c-ad99-5f834b848421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Cyclic_Env(Abstract_Env):\n",
    "    \"\"\"\n",
    "    An environment that cycles deterministically through a sequence of percepts that may be passed to an agent\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 percept_cycle: np.ndarray,\n",
    "                 initial_state: int = 0):\n",
    "        self.percept_cycle = percept_cycle\n",
    "        state = initial_state\n",
    "        super().__init__(state = state)\n",
    "\n",
    "    def transition(self):\n",
    "        \"\"\"\n",
    "        This environment has deterministic transitions and does not take actions as input\n",
    "        \"\"\"\n",
    "        self.state = (self.state + 1) % len(self.percept_cycle)\n",
    "\n",
    "    def get_observation(self):\n",
    "        return self.percept_cycle[self.state:self.state+1] #slicing returns array instead of scalar    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644659b-6c4e-4557-b203-88cf5981cf5c",
   "metadata": {},
   "source": [
    "## Example\n",
    "In this example, we set up a cyclical environment in which a light turns green, turns off, turns blue, turns off, and then repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b38655-fc22-4b86-9ce8-547eb499899e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['green'], dtype='<U5'),\n",
       " array(['off'], dtype='<U5'),\n",
       " array(['blue'], dtype='<U5'),\n",
       " array(['off'], dtype='<U5'),\n",
       " array(['green'], dtype='<U5'),\n",
       " array(['off'], dtype='<U5'),\n",
       " array(['blue'], dtype='<U5'),\n",
       " array(['off'], dtype='<U5')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percept_cycle = np.array([\"green\", \"off\", \"blue\", \"off\"])\n",
    "light_cycle_instance1 = Cyclic_Env(percept_cycle)\n",
    "T = 8 #total time steps to simulate\n",
    "observed_percepts = [\"None\"] * T #data structure for storing observations\n",
    "\n",
    "#simulate for T steps and store observations\n",
    "for t in range(T):\n",
    "    observed_percepts[t] = light_cycle_instance1.get_observation()\n",
    "    light_cycle_instance1.transition()\n",
    "\n",
    "observed_percepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a92b1c-3bb5-48b4-a455-b3a9a450c60a",
   "metadata": {},
   "source": [
    "We can also choose to initiate anywhere in the cycle by giving the desired index. In this example, we start in State 2, which returns the \"blue\" percept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f35da0-0d0e-4e36-b709-dc11478ba33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['blue'], dtype='<U5'),\n",
       " array(['off'], dtype='<U5'),\n",
       " array(['green'], dtype='<U5'),\n",
       " array(['off'], dtype='<U5'),\n",
       " array(['blue'], dtype='<U5'),\n",
       " array(['off'], dtype='<U5'),\n",
       " array(['green'], dtype='<U5'),\n",
       " array(['off'], dtype='<U5')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_cycle_instance2 = Cyclic_Env(percept_cycle, initial_state = 2)\n",
    "T = 8 #total time steps to simulate\n",
    "observed_percepts = [\"None\"] * T #data structure for storing observations\n",
    "\n",
    "#simulate for T steps and store observations\n",
    "for t in range(T):\n",
    "    observed_percepts[t] = light_cycle_instance2.get_observation()\n",
    "    light_cycle_instance2.transition()\n",
    "    \n",
    "observed_percepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf478d5-759e-4ca2-8ae0-4b0824a6791b",
   "metadata": {},
   "source": [
    "# RLGL\n",
    "\n",
    "A description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff298852-78ee-4800-b426-4e4afbab6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RLGL(Abstract_Env):\n",
    "    def __init__(self, state = 0, transition_matrix = None):\n",
    "        self.state = state\n",
    "        self.state_labels = {0: \"red\", 1: \"green\"}\n",
    "        if transition_matrix is None:\n",
    "            #create random uniform transition probabilities\n",
    "            transition_matrix = np.array([[0.5,0.5],[0.5,0.5]])\n",
    "        assert np.shape(transition_matrix) == (2,2)\n",
    "        self.transition_matrix = transition_matrix            \n",
    "\n",
    "    def transition(self, action):\n",
    "        '''\n",
    "        In this environment the agents action determines the reward but does not determine the state\n",
    "        '''\n",
    "        self.state = np.random.choice(range(2), p = self.transition_matrix[self.state,])\n",
    "\n",
    "    def get_observation(self):\n",
    "        return self.state_labels[self.state]\n",
    "\n",
    "    def get_reward(self, action):\n",
    "        if action == self.state:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944c7dcc-d445-4c40-8538-c731135075e1",
   "metadata": {},
   "source": [
    "A minimal example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e95f7-55fc-4cd6-8ec8-249d4669be0e",
   "metadata": {},
   "source": [
    "# Causal Dynamic Bayesian Network\n",
    "This environment implements a specific kind of Dynamic Bayesian Network in which variables are not allowed to have parents in the same time step. This the state of all variables at a given time are conditionally independent given the state of the system in the previous time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd3c1fe8-4eac-42ae-ab55-bf04e414849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import inspect\n",
    "class Causal_DBN(Abstract_Env):\n",
    "    def __init__(self,\n",
    "                 state: np.ndarray, #a one dimensional array. Each element gives the state of a variable.\n",
    "                 causal_network: np.ndarray, #a square boolean array that indicates whether a variable at t is a parent of another variable at t+1\n",
    "                 update_functions: dict, #a dictionary of the functions used to update each variable\n",
    "                 variable_names: np.ndarray = None, #an optional list of variables names. Default is integers. Must match keys of update functions\n",
    "                 action_variables: np.ndarray = None #indicates which system variables are under the control of an agent. Used to ensure inputs to transition function are correct\n",
    "                ):\n",
    "        if variable_names is None:\n",
    "            variable_names = np.array(range(self.num_variables))\n",
    "\n",
    "        #check variables\n",
    "        if not state.ndim == 1:\n",
    "            raise ValueError(\"'state' must be a numpy array with a single dimension\")\n",
    "        self.num_variables = np.shape(state)[0]\n",
    "\n",
    "        assert causal_network.dtype == np.bool_\n",
    "        if not np.shape(causal_network) == (self.num_variables, self.num_variables):\n",
    "            raise ValueError(\"causal network must be a square matrix with each dimension equal to the number of variables given by the state input\")\n",
    "\n",
    "        if action_variables is None:\n",
    "            action_variables = np.full(self.num_variables, fill_value = False)\n",
    "        for action_variable in variable_names[action_variables]:\n",
    "            update_functions[action_variable] = self.action_function        \n",
    "        for key, update_f in update_functions.items():\n",
    "            if not key in variable_names:\n",
    "                raise ValueError(\"Keys of update_function dictionary must correspond to variable names. Default variable names are integer indices\")\n",
    "            assert callable(update_f)            \n",
    "            ## Check that update function inputs match causal_network\n",
    "            function_parents = list(inspect.signature(update_f).parameters)\n",
    "            i = np.where(variable_names == key)[0][0] #get parent index (indexes get first match in first dimension)\n",
    "            if not set(function_parents) == set(variable_names[causal_network[:,i]]): #compare input variables names to children in DBN\n",
    "                raise ValueError(f'The update function for {variable_names[i]} does not have input variables that match parents in causal_network')\n",
    "\n",
    "        if not len(update_functions) == self.num_variables:\n",
    "            raise ValueError(\"there must be an update function for each variable in 'state'\")\n",
    "\n",
    "\n",
    "        self.state = state\n",
    "        self.causal_network = causal_network\n",
    "        self.update_functions = update_functions\n",
    "        self.variable_names = variable_names\n",
    "        self.action_variables = action_variables\n",
    "\n",
    "    def transition(self, action: dict = None):\n",
    "        if action is None:\n",
    "            action = {}\n",
    "\n",
    "        #update action states\n",
    "        for key, value in action.items():\n",
    "            if not key in self.variable_names:\n",
    "                raise ValueError(\"keys of action dictionary must be environment variable names\")\n",
    "            self.state[self.variable_names == key] = value\n",
    "\n",
    "        #apply transition functions\n",
    "        new_states = np.zeros(self.num_variables)\n",
    "        for variable, update_f in self.update_functions.items():\n",
    "            required_args = set(inspect.signature(update_f).parameters.keys())\n",
    "            input_dict = {k: v for k, v in zip(self.variable_names, self.state) if k in required_args}\n",
    "            new_states[self.variable_names == variable] = update_f(**input_dict)\n",
    "        self.state = new_states\n",
    "\n",
    "    def get_observation(self):\n",
    "        return self.state\n",
    "    \n",
    "    def action_function(self, x): #as actions are given as input, the stored update functions for these variables should not do anything\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682565d-fba1-4b12-b2f3-5311734e54a0",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fda83d8c-92fc-482b-803b-4bb292a28883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = np.array((1.,2.,True))\n",
    "causal_network = np.array([[False,False,True],\n",
    "                           [False,False,True],\n",
    "                           [False,False,False]]\n",
    "                         )\n",
    "def Bernoulli():\n",
    "    return np.random.binomial(1,0.5)\n",
    "def Pair_Match(a,b):\n",
    "    return a == b\n",
    "update_functions = {\"a\": Bernoulli, \"b\": Bernoulli, \"test\": Pair_Match}\n",
    "variable_names = np.array([\"a\", \"b\", \"test\"])\n",
    "test_DBN = Causal_DBN(state, causal_network, update_functions, variable_names)\n",
    "test_DBN.transition()\n",
    "test_DBN.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edc8d1ba-eae8-4030-88c9-5735940226cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pair_Match(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb50f95d-d56e-42be-8844-41b0b3679d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7ad2b-e158-47dd-bb98-b5f7acc6f363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
