{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2454d3c4",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "This module contains different types of episodic and compositional memories (ECMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6c27c4-41b7-4367-814f-1ac318d674fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ECMs.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d38fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71df5a",
   "metadata": {},
   "source": [
    "## ECMs constructors\n",
    "\n",
    "Here we collect different standalone functions that will help us construct different types of ECM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebfd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def standard_ps_upd(reward, hmatrix, gmatrix, h_damp, g_damp):\n",
    "    \n",
    "    '''\n",
    "    Given a reward, updates h-matrix and g-matrix following the standard PS update rule:\n",
    "\n",
    "    $h \\leftarrow h - h_{damp}*(h-1)+ reward*g$\n",
    "    \n",
    "    $g \\leftarrow (1-g_{damp})*g$   \n",
    "    '''\n",
    "    \n",
    "    # damping h-matrix\n",
    "    hmatrix = hmatrix - h_damp*(hmatrix-1.)\n",
    "    # update h-matrix\n",
    "    hmatrix += reward*gmatrix\n",
    "    # update g-matrix\n",
    "    gmatrix = (1-g_damp)*gmatrix\n",
    "\n",
    "    return hmatrix, gmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa87bdf",
   "metadata": {},
   "source": [
    "## Pre-built ECMs\n",
    "\n",
    "Here we collect the abstract parent class that any ECM should be built upon as well as some pre-built ECM ready to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5475b4-a17f-44f1-ba9c-3ace43286a47",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "### Abstract ECM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bbeb219-d8ac-427c-8d02-868a3c884b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from projective_simulation.methods.lib_helpers import CustomABCMeta\n",
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "class Abstract_ECM(metaclass = CustomABCMeta):\n",
    "    \"\"\"\n",
    "    Abstract agent class any episodic and compositional memory (ECM) should be derived from. \n",
    "    Asserts that the necessary methods are implemented.\n",
    "    No compulsory input objects are needed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        No restrictions on the constructor, as the ECM can be anything that has a sample module.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample(self,):\n",
    "        \"\"\"\n",
    "        Performs a random walk through the ECM. Typically, this implies receiving an input percept and returning an action.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dd3f1-39fa-49a2-b52c-7ba94353d5e4",
   "metadata": {},
   "source": [
    "PS agents must have as parent class `Abstract_ECM`, and hence must contain one compulsory method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a680f4e-a661-4246-b5e7-ba2c00aa0f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/{user}/projective_simulation/blob/master/projective_simulation/ECMs/core.py#L40){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "#### Abstract_ECM.sample\n",
       "\n",
       ">      Abstract_ECM.sample ()\n",
       "\n",
       "*Performs a random walk through the ECM. Typically, this implies receiving an input percept and returning an action.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/{user}/projective_simulation/blob/master/projective_simulation/ECMs/core.py#L40){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "#### Abstract_ECM.sample\n",
       "\n",
       ">      Abstract_ECM.sample ()\n",
       "\n",
       "*Performs a random walk through the ECM. Typically, this implies receiving an input percept and returning an action.*"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Abstract_ECM.sample, title_level = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bab47e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the expected TypeError, test passed.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "### Test ###\n",
    "\n",
    "class test_abstract(Abstract_ECM):\n",
    "\n",
    "    def __init__(self, num_actions = 2):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    # Here we do not define on purpose the sample method, to check if the abstract class raises an error when trying to instantiate it.\n",
    "    # def sample(self):\n",
    "    #     return 0\n",
    "\n",
    "try:\n",
    "    agent = test_abstract()  # This should raise a TypeError\n",
    "except TypeError:\n",
    "    print(\"Got the expected TypeError, test passed.\")\n",
    "else:\n",
    "    raise AssertionError(\"TestAgent() did NOT raise TypeError but it should have.\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93a56c-8778-4f41-93c7-6e917f669250",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## Two Layer ECM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de96b30c-66ed-448a-806d-64978cab7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import numpy as np\n",
    "from projective_simulation.methods.transforms import _softmax\n",
    "\n",
    "class Two_Layer(Abstract_ECM):\n",
    "    def __init__(self, \n",
    "                 # The number of available actions.\n",
    "                 num_actions: int, \n",
    "                 # The glow damping(or eta) parameter. \n",
    "                 g_damp: float, \n",
    "                 # The damping (or gamma) parameter. \n",
    "                 h_damp: float,\n",
    "                 # If 'greedy', uses a greedy policy that samples the most action based on the h-matrix. \n",
    "                 # If 'softmax', uses a softmax policy that samples an action based on the h-matrix and a temperature parameter (encoded in policy_parameters).\n",
    "                 # If object, uses this object to sample action. Input must be h_values corresponding to current percept + arbitrary policy_parameters.\n",
    "                 policy: str = 'greedy',                 \n",
    "                 # The parameters of the policy.\n",
    "                 policy_parameters: dict = None,\n",
    "                 # Method to update the g-matrix. \n",
    "                 # If 'sum', adds the new value to the current value.\n",
    "                 # If 'init', sets the new value to 1.\n",
    "                 glow_method: str = 'sum',\n",
    "                ):\n",
    "\n",
    "        \"\"\"\n",
    "        Two layer ECM. First layer, encoding the percepts observed in an environment, is initially empty (e.g. self.num_percepts = 0). \n",
    "        As percepts are observed, they are added to the ECM and to the percept dictionary self.percepts. \n",
    "        The second layer, encoding the actions, has size self.num_actions.\n",
    "        In practice, the ECM graph is never created. \n",
    "        Instead, it is defined indirectly by the h-matrix and g-matrix. \n",
    "        Both have size (self.num_percepts, self.num_actions). \n",
    "        The input policy (greedy, softmax or other) is used to sample actions based on the h-matrix.\n",
    "\n",
    "        For an end-to-end example of how to use this class, see the introductory tutorial notebook on PS agents.        \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.h_damp = h_damp\n",
    "        self.g_damp = g_damp\n",
    "        self.glow_method = glow_method\n",
    "\n",
    "        self.policy = policy\n",
    "        self.policy_parameters = policy_parameters\n",
    "        \n",
    "        # Initialize ECM structures\n",
    "\n",
    "        #int: current number of percepts.\n",
    "        self.num_percepts = 0\n",
    "        #np.ndarray: h-matrix with current h-values. Defaults to all 1.\n",
    "        self.hmatrix = np.ones([0,self.num_actions])\n",
    "        #np.ndarray: g-matrix with current glow values. Defaults to all 0.\n",
    "        self.gmatrix = np.zeros([0,self.num_actions])\n",
    "        #dict: Dictionary of percepts as {\"percept\": index}\n",
    "        self.percepts = {}\n",
    "\n",
    "    def sample(self, percept: str):\n",
    "        \"\"\"\n",
    "        Given a percept, returns an action and changes the ECM if necessary\n",
    "        First, if the percept is new, it will be added to the ECM\n",
    "        Then, an action is selected as a function of the percept and the h-values of edges connected to that percept\n",
    "        Finally, the g-matrix is updated based on the realized percept-action pair.\n",
    "        \"\"\"\n",
    "\n",
    "        # Add percept to ECM if not already present\n",
    "        self.add_percept(percept)\n",
    "        # Get index from dictionary entry\n",
    "        percept_index = self.percepts[percept]\n",
    "        # Get h-values\n",
    "        h_values = self.hmatrix[percept_index]\n",
    "\n",
    "        # Perform Random Walk through the ECM based on h_values and current policy\n",
    "        if self.policy == 'greedy': \n",
    "            # Sample greedly the action with the highest h-value\n",
    "            h_values = self.hmatrix[percept_index]\n",
    "            action = h_values.argmax()   \n",
    "\n",
    "        elif self.policy == 'softmax':\n",
    "            # Get probabilities from h-values through a softmax function\n",
    "            prob = _softmax(self.policy_parameters, h_values)\n",
    "            # Sample action based on probabilities\n",
    "            action = np.random.choice(range(self.num_actions), p=prob) \n",
    "\n",
    "        else:\n",
    "            # This considers a custom policy\n",
    "            action = self.policy(h_values = h_values, **self.policy_parameters)\n",
    "\n",
    "        # Update g-matrix\n",
    "        if self.glow_method == 'sum':\n",
    "            self.gmatrix[int(percept_index),int(action)] += 1.\n",
    "        if self.glow_method == 'init':\n",
    "            self.gmatrix[int(percept_index),int(action)] = 1.   \n",
    "\n",
    "        return action\n",
    "\n",
    "    def add_percept(self, percept):\n",
    "        '''\n",
    "        Checks if percept is in dictionary and adds to ECM in not\n",
    "        '''\n",
    "        if percept not in self.percepts.keys(): \n",
    "            self.percepts[percept] = self.num_percepts\n",
    "            # increment number of percepts\n",
    "            self.num_percepts += 1\n",
    "            # add column to h-matrix\n",
    "            self.hmatrix = np.append(self.hmatrix, \n",
    "                                     np.ones([1,self.num_actions]),\n",
    "                                     axis=0)\n",
    "            # add column to g-matrix\n",
    "            self.gmatrix = np.append(self.gmatrix, \n",
    "                                    np.zeros([1,self.num_actions]),\n",
    "                                    axis=0)\n",
    "\n",
    "    def learn(self, reward):\n",
    "        \"\"\"\n",
    "        Updates the h-matrix and g-matrix based on the reward received using the standard PS update rule.\n",
    "        \"\"\"\n",
    "        self.hmatrix, self.gmatrix = standard_ps_upd(reward, self.hmatrix, self.gmatrix, self.h_damp, self.g_damp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa5563-840e-4f53-b24e-1ca1b0d2ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Two_Layer.__init__, name = 'Two_Layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d52db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "### Test ###\n",
    "\n",
    "# Greedy policy\n",
    "ECM_2l_greedy = Two_Layer(4,1,1)\n",
    "ECM_2l_greedy.sample(0)\n",
    "\n",
    "# Softmax policy\n",
    "ECM_2l_softmax = Two_Layer(4,1,1, policy = 'softmax', policy_parameters = 1)\n",
    "ECM_2l_softmax.sample(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bfdddd",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# nbdev export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PS",
   "language": "python",
   "name": "ps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
