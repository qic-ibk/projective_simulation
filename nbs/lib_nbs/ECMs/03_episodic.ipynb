{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b697d09d-0a74-4c0d-af7b-6e90645207c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ECMs.episodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7ec30e-b1c7-41b3-9936-3eb1151d209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import scipy\n",
    "from projective_simulation.ECMs.abstract_ECM import ECM\n",
    "from projective_simulation.utils import _softmax\n",
    "\n",
    "class Episodic_Memory(ECM):\n",
    "    def __init__(self,\n",
    "                 num_actions: int,\n",
    "                 capacity: int = 10,\n",
    "                 softmax: float = 0.7,\n",
    "                 focus: float = 1.,\n",
    "                 error_tolerance: float = 0.01,\n",
    "                 min_expectation: float = 0.01,\n",
    "                 deliberation_length: int = 1,\n",
    "                 t: int = 0,\n",
    "                ):\n",
    "        '''\n",
    "        The episodic memory ECM stores percept information in a time ordered system of memory traces by establishing connections (trace_encoder) with weights (hmatrix) between excited perceptual representations and an excited memory trace.\n",
    "        The agent maintains a belief state through the activation (different from excitation) of memory traces, where the strength of activation reflects the strength of the agent's belief that its current state-in-the-world is effectively the same as a state-in-the-world represented by that memory trace\n",
    "        The agent also maintains an expectation state by priming perceptual representations as a function of (1) its belief state, (2) connections between memory traces (mmatrix, stricly time-ordered in this implementation), and (3) the h-matrix\n",
    "        The difference between the agent's expectation state and the excitation of perceptual represenations in the next time step is computed as a surprise and assigned to the last excited memory trace as a valence state\n",
    "        Perceptual representations are excited as a function of sensory-motor interactions with the world and the agent's expectation state\n",
    "        Memory Traces are excited in a time-ordered, winner-takes all fashion.\n",
    "        The agent's beliefs are updated by a process of deliberation, in which excited perceptual representations are activated and those activations then diffuse across the ECM as if they were caused by particles performing a random walk on the ECM graph\n",
    "        The probability that an activation particle walks from one node to another is a function of the edge weights in the hmatrix connected to its current node (perceptual representation or memory trace), and the belief states and valence states of all nodes to which those edges lead\n",
    "        The focus parameter of the Episodic ECM adds weight to a single departing edge from each node, adding stochastic bias to the random walk. Rewards reinforce edge weights in the ECM proportionally to the difference between the expected particle mass to traverse that edge and the observed mass\n",
    "        Rewards are determined as a function of the \"surprise advantage\", i.e. how much more or less surprised the agent was then on average over its previous (relevant) experience.\n",
    "\n",
    "        inputs\n",
    "        num_actions: the number of perceptual representations available to the agent which, when excited, have an effect on the agent's environment. Action representations are primed differently than sensory representations and do not affect surprise\n",
    "        capacity: the number of memory traces avaiable to the agent. If simulation time exceeds capacity, the oldest memory trace will be overwritten each time step\n",
    "        softmax: to determine random walk probailities, edge weights are normalized using a softmax function with this variable as the temperature constant\n",
    "        t: used to model the temporal excitation sequence of memory traces\n",
    "        focus:  Focus scales the effect of stochastic processes underlying random walks on the ECM. (i.e. it scales the effect of Projective Simulation)\n",
    "                Think of deliberation in an Episodic ECM like a very large number of particles diffusing on the ECM graph, but at each node a single particle is chosen at random and some proportion of particles are pulled along with that one. Focus defines that proportion\n",
    "                If focus == 1, deliberation acts as a random walk of a single (massive) particle on the ECM. \n",
    "                If focus == 0, deliberation acts as the diffusion of a large (approaching infinite) number of particles on the ECM\n",
    "        error_tolerance: How strongly the agent discounts the similarity between two states per bit of mismatched sensory information when establishing a new belief state\n",
    "        min_expectation: a baseline value for the priming of perceptual representations. Must be greater than 0 to prevent infinate surprise if a perceptual representation is excited that was not predicted by the agents belief state\n",
    "        deliberation_length: the number of diffusive steps in the agent's deliberations\n",
    "        '''\n",
    "\n",
    "        #initialize constants\n",
    "        self.num_actions = num_actions\n",
    "        self.capacity = capacity\n",
    "        self.softmax = 0.7 \n",
    "        self.focus = focus \n",
    "        self.error_tolerance = error_tolerance\n",
    "        self.min_expectation = min_expectation\n",
    "        self.deliberation_length = deliberation_length\n",
    "        self.surprise: float = None\n",
    "        \n",
    "        #initialize modelling variables\n",
    "        self.t = t\n",
    "\n",
    "        #initialize ECM states\n",
    "        self.hmatrix = np.zeros((self.num_actions, self.capacity)) #weights connecting percept nodes to trace nodes\n",
    "        self.mmatrix = np.zeros((self.capacity, self.capacity)) #initialize with no connections between memory traces\n",
    "        self.trace_encoder = np.zeros((self.num_actions, self.capacity), dtype = 'bool') #boolean matrix indicating whether a percept node was encoded in a trace\n",
    "        self.action_encoder = np.ones(self.num_actions, dtype = 'bool') #boolean matrix indicated whether a percept node belongs to an action\n",
    "        self.expectations = np.zeros(self.num_actions) + self.min_expectation\n",
    "        self.beliefs = np.zeros(self.capacity) #initilize with no belief weight on any memory traces\n",
    "        self.valences = np.array([np.nan] * self.capacity) #use nan here because we will want to takes means of this array as it is filled\n",
    "        self.percept_activations = np.zeros(np.shape(self.hmatrix)[0]) #initialize with no activation of percept nodes\n",
    "        self.trace_activations = np.zeros(self.capacity) #initialize with no activation of memory traces\n",
    "        self.trace_excitations = np.zeros(self.capacity) #trace excitations represent the sensory evidence that the world is currently in a state that is effectively represented by the excited trace\n",
    "        \n",
    "\n",
    "    def deliberate(self, percept):\n",
    "        self.add_percept(percept)\n",
    "        self.surprise = self.get_surprise(percept)\n",
    "        self.excite_traces(percept)\n",
    "        self.encode_trace(percept)\n",
    "        self.activate()\n",
    "        for deliberation_step in range(self.deliberation_length):\n",
    "            self.diffuse_activation()\n",
    "        self.predict()\n",
    "        self.t = (self.t + 1) % self.capacity\n",
    "        return(self.expectations[self.action_encoder]) #return action priming\n",
    "\n",
    "    def add_percept(self, percept):\n",
    "        if len(percept) > np.shape(self.hmatrix)[0]: #if percept is longer than the first dimension of the hmatrix it means there is something new in the observation (handled by preprocessor)\n",
    "            i = np.shape(self.hmatrix)[0] #get index for new elements in ECM\n",
    "            new_elements = percept[i:len(percept)]    \n",
    "            self.hmatrix = np.append(self.hmatrix, np.zeros((len(new_elements), self.capacity)), axis = 0) #add baseline weights to connections between new percept nodes and all traces\n",
    "            self.trace_encoder = np.append(self.trace_encoder, np.zeros((len(new_elements), self.capacity), dtype = 'bool'), axis = 0) #new percept nodes have no existing connections to trace nodes\n",
    "            self.action_encoder = np.append(self.action_encoder, np.zeros(len(new_elements), dtype = 'bool')) #this ECM does not support new actions, so new percept nodes are sensory by default\n",
    "            self.expectations = np.append(self.expectations, np.zeros(len(new_elements)) + self.min_expectation)\n",
    "\n",
    "    def excite_traces(self, percept):\n",
    "        self.trace_excitations = np.zeros(self.capacity)\n",
    "        # each trace is excited proportionally to the probability that of the n connections it has to perceptual representations, r of those perceptual representations are excited . . .\n",
    "        # . . . if that trace effectively represents the current world state . . .\n",
    "        # . . . and sensory_error gives the probability that a connected sensory_representation fails to excite when the world is in the state represented by the memory trace.\n",
    "        # this probability is given by the binomial distribution\n",
    "        for t_index in range(self.capacity):\n",
    "            n = np.sum(self.trace_encoder[0:,t_index])\n",
    "            if n > 0: #no excitation if trace has no connections (functionally this shouldn't matter, but it is nicer for interpretation)\n",
    "                r = np.sum([self.trace_encoder[p_index,t_index] and percept[p_index] for p_index in range(len(percept))]) # for each percept, checks that it is both excited and connected to trace, then counts\n",
    "                self.trace_excitations[t_index] = scipy.stats.binom.pmf(r,n,p = 1-self.error_tolerance)\n",
    "    \n",
    "    def encode_trace(self, percept):\n",
    "        self.trace_encoder[0:,self.t] = [x > 0 for x in percept] #connect all excited percepts to current trace\n",
    "        self.mmatrix[self.t-1,self.t] = 1 #create forward connection from previous trace to current trace (this is a spurious but inconsequential connection for an agent's first step)\n",
    "        self.mmatrix[self.t,0:] = [0 for x in self.mmatrix[self.t,0:]] #break any forward connections from current trace (only relevant if t is greater than self.capacity)\n",
    "        self.valences[self.t-1] = self.surprise #valence is assigned to the last trace, it relfects how surprised the agent was by the outcome of the action it took in that trace\n",
    "    \n",
    "    def activate(self):\n",
    "        activation_weights = _softmax(self.softmax, self.hmatrix[self.trace_encoder[0:,self.t],self.t]) #softmax function over edge weights connected to current memory trace\n",
    "        random_selection = np.random.choice(range(len(activation_weights)), p = activation_weights) #get destination of PS random walk\n",
    "        self.percept_activations = np.zeros(np.shape(self.hmatrix)[0]) #reset activations\n",
    "        #bias activation toward starting node of PS random walk\n",
    "        self.percept_activations[self.trace_encoder[0:,self.t]] = [activation_weights[i] + self.focus*(1-activation_weights[i]) if i == random_selection else activation_weights[i] * (1-self.focus) for i in range(len(activation_weights))]\n",
    "\n",
    "    def diffuse_activation(self):\n",
    "        new_trace_activations = np.zeros(self.capacity)\n",
    "        for i in range(np.shape(self.hmatrix)[0]):\n",
    "            #edge weights are the product of the the edge h-values exponent (relevance), the activation of the trace to which the edge is connected (belief prior), and the excitation of the trace to which the edge is connected (sensory evidence)\n",
    "            edge_weights = np.multiply(np.exp(self.hmatrix[i,self.trace_encoder[i,0:]]), self.trace_activations[self.trace_encoder[i,0:]], self.trace_excitations[self.trace_encoder[i,0:]])\n",
    "            if len(edge_weights) > 0: #dont diffusion activation if there are no edges (there should not be to activation to diffuse)    \n",
    "                edge_probs = _softmax(self.softmax, edge_weights)\n",
    "                random_selection = np.random.choice(range(len(edge_weights)), p = edge_probs) #get destination of Projective Simulations\n",
    "                diffusion_mass = _get_diffusion_mass(self.percept_activations[i], edge_probs, random_selection, self.focus)\n",
    "                new_trace_activations[self.trace_encoder[i,0:]] = new_trace_activations[self.trace_encoder[i,0:]] + diffusion_mass\n",
    "        self.trace_activations = new_trace_activations\n",
    "\n",
    "    def predict(self):\n",
    "        self.trace_activations = np.matmul(self.trace_activations, self.mmatrix) # because each row of the matrix has either zeros or a single 1, this just propogates attention forward. non-linear functions might be necessary for more complex mmatrix structures\n",
    "        self.expectations = np.zeros(np.shape(self.hmatrix)[0]) + self.min_expectation #hmatrix rows correspond to perceptual representations\n",
    "        for trace in range(self.capacity):\n",
    "            action_modifiers = np.exp(self.action_encoder * (np.nanmean(self.valences) - self.valences[trace])) #used to scale priming of action representations as a function of trace valence\n",
    "            self.expectations = self.expectations + self.trace_activations[trace] * np.multiply(self.trace_encoder[0:,trace], action_modifiers)\n",
    "\n",
    "    def get_surprise(self, percept):\n",
    "        not_action = np.invert(self.action_encoder) #used to exclude action representations from surprise computations\n",
    "        return np.sum(np.where(percept[not_action], -np.log2(self.expectations[not_action]), -np.log2(1-self.expectations[not_action])))\n",
    "            \n",
    "def _get_diffusion_mass(activation, edge_probs, random_selection, focus):\n",
    "    #gets the activation mass that diffuses along each edge connected to a perceptual representation. Note the different effect of the focus parameter if the edge was selected by PS random walk\n",
    "    diffusions = [None] * len(edge_probs)\n",
    "    for i in range(len(edge_probs)):\n",
    "        if i == random_selection:\n",
    "            diffusions[i] = activation * (edge_probs[i] + focus*(1-edge_probs[i]))\n",
    "        else:\n",
    "            diffusions[i] = activation * edge_probs[i] * (1 - focus)\n",
    "    return(diffusions)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0509bf27-3b31-4e03-9018-f24763f596a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Episodic_Memory(num_actions = 2, focus = 0.5)\n",
    "test.mmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82eafd4a-4ec1-4bd3-ad1d-ebd0ecded281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.deliberate(np.array([1,0,1,0]))\n",
    "test.expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73b90d7-c0fa-447b-8840-b58393b09fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.658355759469839"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8e7628-3b68-4de3-bf74-79cdd34a0318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [ True, False, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.trace_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f938a5-3886-493a-9423-e785075fd872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793935c0-5ad5-4fec-af49-5e1f98f3472b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
