{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc9571-7db1-4b94-a383-c154204a7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp methods.preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c73ff2-5d94-4505-a07a-eaa6c8f5b073",
   "metadata": {},
   "source": [
    "# Get percept\n",
    "> Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc75263-8588-4218-af45-f43d33fe9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_percept(observation):\n",
    "    percept = str(observation)\n",
    "    return(percept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab5a85-192e-4398-887e-297937b8ed80",
   "metadata": {},
   "source": [
    "# Factorizor methods\n",
    "> Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a43bbf-bebf-422e-9a0e-a74632fc8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "\n",
    "class factorizor():\n",
    "    def __init__(self, percept_dict = {}):\n",
    "        self.percept_dict = percept_dict\n",
    "    '''\n",
    "    This preprocessor maintains a dictionary of all sensory elements and the order of their appearance.\n",
    "    This order can be used to index the corresponding sensory representation in an ECM with factorized percepts such as the episodic ECM\n",
    "    The dictionary keys a subdictionary for each dimension of an observational vector. Realized values key the sub-dictionary, and values of these subdictiories give the index of the relevant sensory representation\n",
    "    '''\n",
    "\n",
    "    def get_percept(self, observation):\n",
    "        if type(observation) == int:\n",
    "            observation = [observation]\n",
    "        percept_indices = [None] * len(observation)\n",
    "        for i in range(len(observation)):\n",
    "            if not str(i) in self.percept_dict.keys(): #add new dictionary for any new dimensions in observation\n",
    "                self.percept_dict[str(i)] = {}\n",
    "            if not str(observation[i]) in self.percept_dict[str(i)].keys():\n",
    "                self.percept_dict[str(i)][str(observation[i])] = sum([len(x) for x in self.percept_dict.values()]) #gets total number of entries. First entry is 0, so no need to add 1\n",
    "            percept_indices[i] = self.percept_dict[str(i)][str(observation[i])] #get index of sensory representation for observed element\n",
    "        percept = np.zeros(sum([len(x) for x in self.percept_dict.values()])) #initialize percept\n",
    "        percept[percept_indices] = np.ones(len(observation))\n",
    "        return percept  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2727ce-8945-45af-aa67-a5f2a9e4b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class action_factorizor(factorizor):\n",
    "    '''\n",
    "    This preprocessor acts like factorizor, except it assumes an agent treats a predefined number of actions as a dimension of its percept\n",
    "    It thus intialize its percept dictionary with a dictionary of these n actions that label the first n sensory representations of the agent\n",
    "    It also handles the addition of the observed action to the percept when get_percept is called\n",
    "    '''\n",
    "    def __init__(self, percept_dict = {},num_actions=None):\n",
    "        self.percept_dict = percept_dict\n",
    "        assert 'actions' in self.percept_dict.keys() or num_actions is not None\n",
    "        if num_actions is not None:\n",
    "            self.percept_dict['actions'] = {}\n",
    "            for i in range(num_actions):\n",
    "                self.percept_dict['actions'][str(i)] = i\n",
    "\n",
    "    def get_percept(self, observation, action):\n",
    "        percept = super().get_percept(observation)\n",
    "        action_index = self.percept_dict['actions'][str(action)]\n",
    "        percept[action_index] = 1\n",
    "        return percept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b606b4-d8aa-4359-a6a3-ef848c0100e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
