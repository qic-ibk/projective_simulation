{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0f067-1145-437b-8ecc-90a6844109c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp bayesianNetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4683d-4d7d-4e50-9b9c-62e0091f8063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import projective_simulation.methods.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95657ecc-b873-43e5-b8be-bc7818affef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Bayesian_Network:\n",
    "    def __init__(self, num_sensory_elements, num_m_nodes, W_matrix, C_matrix, m_expectation = None):\n",
    "        self.num_sensory_elements = num_sensory_elements\n",
    "        self.num_m_nodes = num_m_nodes\n",
    "        self.W_matrix = W_matrix  # Shape: (num_sensory_elements, num_m_nodes)\n",
    "        self.C_matrix = C_matrix  # Shape: (num_m_nodes, num_m_nodes)\n",
    "        \n",
    "        # Initialize sensory and m-level variables as empty numpy arrays\n",
    "        self.sensory_excitation = np.empty(np.shape(W_matrix)[0])\n",
    "        self.m_excitation = np.empty(num_m_nodes)\n",
    "        self.m_expectation = np.full(num_m_nodes, fill_value = 1/num_m_nodes) if m_expectation is None else m_expectation\n",
    "        self.sensory_expectation = np.dot(self.m_expectation, self.W_matrix.T)\n",
    "        self.m_activation = np.empty(num_m_nodes)\n",
    "    \n",
    "    def excite_network(self, percept):\n",
    "        \"\"\"Set the sensory excitation and compute m_excitation.\"\"\"\n",
    "        if percept.shape[0] != self.num_sensory_elements:\n",
    "            raise ValueError(\"Percept vector size does not match the number of sensory elements.\")\n",
    "        \n",
    "        self.sensory_excitation = percept  # Set sensory excitation\n",
    "        \n",
    "        # Compute m_excitation using equation 1\n",
    "        self.m_excitation = np.prod(\n",
    "            np.power(self.W_matrix, self.sensory_excitation[:, np.newaxis]) * \n",
    "            np.power(1 - self.W_matrix, (1 - self.sensory_excitation)[:, np.newaxis]),\n",
    "            axis=0\n",
    "        )\n",
    "    \n",
    "    def activate(self):\n",
    "        \"\"\"Compute m_activation based on m_excitation and m_expectation.\"\"\"\n",
    "        numerator = self.m_excitation * self.m_expectation\n",
    "        denominator = np.sum(numerator)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            self.m_activation = np.zeros(self.num_m_nodes)  # Avoid division by zero (network properties are such that this should never happen)\n",
    "        else:\n",
    "            self.m_activation = numerator / denominator\n",
    "    \n",
    "    def set_expectations(self):\n",
    "        \"\"\"Set m_expectation and sensory_expectation based on activation and weight matrices.\"\"\"\n",
    "        \n",
    "        # Normalize C_matrix rows to ensure proper probability distributions\n",
    "        row_sums = self.C_matrix.sum(axis=1, keepdims=True)\n",
    "        normalized_C_matrix = np.divide(self.C_matrix, row_sums, where=row_sums!=0)\n",
    "        \n",
    "        # Compute m_expectation using the normalized C_matrix\n",
    "        self.m_expectation = np.dot(self.m_activation, normalized_C_matrix)\n",
    "        \n",
    "        # Compute sensory_expectation using W_matrix\n",
    "        self.sensory_expectation = transforms._shifted_exp(x = np.dot(self.m_expectation, self.W_matrix.T), k = 0)\n",
    "\n",
    "    def get_surprise(self):\n",
    "        \"\"\"Compute the total surprise of the network.\"\"\"\n",
    "        \n",
    "        # Compute individual sensory surprise values\n",
    "        surprise_values = np.where(\n",
    "            self.sensory_excitation == 1,\n",
    "            -np.log2(self.sensory_expectation),\n",
    "            -np.log2(1 - self.sensory_expectation)\n",
    "        )\n",
    "        \n",
    "        # Sum all sensory surprises to get total surprise\n",
    "        total_surprise = np.sum(surprise_values)\n",
    "        \n",
    "        return total_surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306896c-6db9-4cbf-b482-1548813f73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Bayesian_Memory(Bayesian_Network):\n",
    "    def __init__(self, num_sensory_elements, num_m_nodes, W_matrix=None, C_matrix=None, timer=0, sensory_evidence_prior = 1, continuity_prior = 0.95):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian Memory network.\n",
    "        :param num_sensory_elements: Number of sensory elements.\n",
    "        :param num_m_nodes: Number of memory nodes.\n",
    "        :param W_matrix: Sensory to memory weight matrix, defaults to 0.5 for all weights if None.\n",
    "        :param C_matrix: Memory transition matrix, defaults to zeros if None.\n",
    "        :param timer: Integer tracking memory time index, defaults to 0.\n",
    "        \"\"\"\n",
    "        if W_matrix is None:\n",
    "            W_matrix = np.full((num_sensory_elements, num_m_nodes), fill_value = 0.5)\n",
    "        if C_matrix is None:\n",
    "            C_matrix = np.zeros((num_m_nodes, num_m_nodes))\n",
    "        \n",
    "        super().__init__(num_sensory_elements, num_m_nodes, W_matrix, C_matrix)\n",
    "        self.timer = timer\n",
    "        self.sensory_evidence_prior = sensory_evidence_prior\n",
    "        self.continuity_prior = continuity_prior\n",
    "    \n",
    "    def encode_memory(self):\n",
    "        \"\"\"Modify W_matrix and C_matrix to encode sensory input into memory.\"\"\"\n",
    "        \n",
    "        # Update W_matrix based on sensory excitation\n",
    "        self.W_matrix[:, self.timer] = self.sensory_excitation \n",
    "        \n",
    "        # Update C_matrix based on memory trace\n",
    "        trace = self.timer\n",
    "        self.C_matrix[:, trace] = (1 - self.continuity_prior) / (self.num_m_nodes - 1) #keeps wieghts normalized by default\n",
    "        self.C_matrix[trace - 1, trace] = self.continuity_prior\n",
    "\n",
    "        #remove excitation from encoded trace\n",
    "        self.m_excitation[trace] = 0\n",
    "\n",
    "        self.timer = (self.timer + 1) % self.num_m_nodes\n",
    "\n",
    "    def excite_network(self, percept):\n",
    "        \"\"\"Set the sensory excitation and compute m_excitation.\"\"\"\n",
    "        if percept.shape[0] != np.shape(self.W_matrix)[0]:\n",
    "            raise ValueError(\"Percept vector size does not match the number of sensory elements.\")\n",
    "        \n",
    "        self.sensory_excitation = percept  # Set sensory excitation\n",
    "\n",
    "        weighted_evidence = transforms._logistic(self.W_matrix, x_shift = 0.5, k = self.sensory_evidence_prior)\n",
    "        # Compute m_excitation using equation 1\n",
    "        self.m_excitation = np.prod(\n",
    "            np.power(weighted_evidence, self.sensory_excitation[:, np.newaxis]) *  #changed from the Bayesian Network to apply logistic function\n",
    "            np.power(1 - weighted_evidence, (1 - self.sensory_excitation)[:, np.newaxis]),\n",
    "            axis=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5cdd3-e15a-46c6-ba27-c85e1be702c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Active_Inference_Memory(Bayesian_Memory):\n",
    "    def __init__(self, \n",
    "                 num_sensory_elements,\n",
    "                 num_action_elements, \n",
    "                 num_m_nodes,\n",
    "                 intrinsic_expectations = None,\n",
    "                 W_matrix=None, \n",
    "                 C_matrix=None,\n",
    "                 epsilon = 0.0001,\n",
    "                 timer=0, \n",
    "                 sensory_evidence_prior = 1, \n",
    "                 continuity_prior = 0.95):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian Memory network.\n",
    "        :param num_sensory_elements: Number of sensory elements.\n",
    "        :param num_m_nodes: Number of memory nodes.\n",
    "        :param num_action_elements: number of action elements\n",
    "        :param W_matrix: Sensory to memory weight matrix, defaults to 0.5 for all weights if None.\n",
    "        :param C_matrix: Memory transition matrix, defaults to zeros if None.\n",
    "        :param timer: Integer tracking memory time index, defaults to 0.\n",
    "        \"\"\"\n",
    "        if intrinsic_expectations is None:\n",
    "            self.intrinsic_expectations = np.zeros(num_sensory_elements)\n",
    "        else:\n",
    "            if not len(intrinsic_expectations) == num_sensory_elements:\n",
    "                raise ValueError(\"Intrinsic Expectations must be a 1D vector with length equal to the number of sensory elements\")\n",
    "            self.intrinsic_expectations = intrinsic_expectations\n",
    "        #create W Matrix with rows for both plain sensory elements and active sensory elements\n",
    "        #because other sensory variables are intialized from this matrix, this is all that is needed\n",
    "        if W_matrix is None:\n",
    "            W_matrix = np.full((num_sensory_elements + num_action_elements, num_m_nodes), fill_value = 0.5)\n",
    "            \n",
    "        super().__init__(num_sensory_elements, num_m_nodes, W_matrix, C_matrix, timer, sensory_evidence_prior, continuity_prior)\n",
    "        \n",
    "        #add action elements to sensory variables\n",
    "        self.num_action_elements = num_action_elements\n",
    "        self.action_encoder = np.append(np.zeros(num_sensory_elements), np.ones(num_action_elements)).astype('int') #tracks which sensory elements are actions\n",
    "\n",
    "        #create a vector for memory valences, to which system surprise is encoded\n",
    "        self.memory_valences = np.full(num_m_nodes, fill_value = np.nan)\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def encode_memory(self):\n",
    "        \"\"\"Modify W_matrix, C_matrix, and memory valences to encode sensory input into memory.\"\"\"\n",
    "        self.memory_valences[self.timer-1] = self.get_surprise()\n",
    "        super().encode_memory()\n",
    "\n",
    "    def set_expectations(self):\n",
    "        \"\"\"Set m_expectation and sensory_expectation based on activation, valence, and weight matrices.\"\"\"\n",
    "        \n",
    "        # Normalize C_matrix rows to ensure proper probability distributions\n",
    "        row_sums = self.C_matrix.sum(axis=1, keepdims=True)\n",
    "        normalized_C_matrix = np.divide(self.C_matrix, row_sums, where=row_sums!=0)\n",
    "        \n",
    "        # Compute m_expectation using the normalized C_matrix\n",
    "        self.m_expectation = np.dot(self.m_activation, normalized_C_matrix)\n",
    "        \n",
    "        # Compute weight adjustments based on suprise advantage and action encoder\n",
    "        priming = np.log(np.nanmean(self.memory_valences)/self.memory_valences)  #used to scale priming of active sensory elements as a function of trace valence\n",
    "        priming[np.isnan(priming)] = 0 #traces without valence do not prime (including current trace)\n",
    "        adjusted_weights = np.power(priming[:,np.newaxis], self.action_encoder) * self.W_matrix.T #multiplies weights to active sensory elements by memory trace suprise advantage (and weight to regular sensory elements by 1)\n",
    "        self.sensory_expectation = np.dot(self.m_expectation, adjusted_weights)\n",
    "        #adjust expectation based on intrinsic expectations\n",
    "        #note that this code depends on all plain sensory elements preceding all action representations in the action encoder \n",
    "        self.sensory_expectation = np.array([self.sensory_expectation[i] if self.action_encoder[i] == 1 else transforms._shifted_exp(self.sensory_expectation[i], k = self.intrinsic_expectations[i], epsilon = self.epsilon) for i in range(len(self.sensory_expectation))])\n",
    "\n",
    "    def get_surprise(self):\n",
    "        \"\"\"Compute the total surprise of the network.\"\"\"\n",
    "        notaction_encoder = [not action for action in self.action_encoder.astype('bool')]\n",
    "        plain_sensory_excitation = self.sensory_excitation[notaction_encoder]\n",
    "        # Compute individual sensory surprise values\n",
    "        surprise_values = np.where(\n",
    "            plain_sensory_excitation == 1,\n",
    "            -np.log2(self.sensory_expectation[notaction_encoder]),\n",
    "            -np.log2(1 - self.sensory_expectation[notaction_encoder])\n",
    "        )\n",
    "        \n",
    "        # Sum all sensory surprises to get total surprise\n",
    "        total_surprise = np.sum(surprise_values)\n",
    "        \n",
    "        return total_surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde11a5-a119-4372-8cb4-0450483b7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Basic_Agent():\n",
    "    def __init__(self,active_inference_memory, action_softmax_temp = 1):\n",
    "        self.memory_network = active_inference_memory\n",
    "        self.num_actions = active_inference_memory.num_action_elements\n",
    "        self.action = None\n",
    "        self.action_softmax_temp = action_softmax_temp\n",
    "\n",
    "    def get_action(self):\n",
    "        '''\n",
    "        choose an action based on expectations of memory network set in previous step\n",
    "        '''\n",
    "        primes = self.memory_network.sensory_expectation[self.memory_network.action_encoder.astype('bool')]\n",
    "        primes_softmax = transforms._softmax(self.action_softmax_temp,primes) #use softmax to nomormalize over real values and get probabilities\n",
    "        self.action = np.random.choice(self.num_actions, p = primes_softmax)\n",
    "        return(self.action)\n",
    "\n",
    "    def deliberate(self,observation):\n",
    "        '''\n",
    "        evaluate current state and make predictions\n",
    "        '''\n",
    "        action_representation = np.zeros(self.num_actions)\n",
    "        action_representation[self.action] = 1\n",
    "        percept = np.append(observation, action_representation)\n",
    "        self.memory_network.excite_network(percept)\n",
    "        self.memory_network.encode_memory()\n",
    "        self.memory_network.activate()\n",
    "        self.memory_network.set_expectations()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802c3fc-b30d-41f8-a2eb-359e3d059219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Flip_Generator:\n",
    "    def __init__(self, probabilities, transitions, state):\n",
    "        \"\"\"\n",
    "        Initialize the flip generator.\n",
    "        :param probabilities: NxD numpy array of probabilities for generating binary vectors. N gives the number of coins/bits and D the number of system states\n",
    "        :param transitions: DxD numpy array representing state transition probabilities.\n",
    "        :param state: Integer representing the initial state.\n",
    "        \"\"\"\n",
    "        self.probabilities = probabilities\n",
    "        self.transitions = transitions\n",
    "        self.state = state\n",
    "        self.D, self.N = probabilities.shape  # Number of states (D) and vector length (N)\n",
    "        \n",
    "        # Assertions to ensure correct dimensionality\n",
    "        assert transitions.shape == (self.D, self.D), \"Transitions matrix must be DxD.\"\n",
    "        assert probabilities.shape[1] == transitions.shape[1], \"Probabilities and transitions must have the same number of states (D).\"\n",
    "        assert np.allclose(transitions.sum(axis=1), 1), \"Each row of the transition matrix must sum to 1.\"\n",
    "    \n",
    "    def generate(self):\n",
    "        \"\"\"\n",
    "        Generate a binary vector based on the current state and transition probabilities.\n",
    "        :return: Generated binary array (1D numpy array of length N)\n",
    "        \"\"\"\n",
    "        # Generate a binary vector where each element is 1 with probability P_{i, j}\n",
    "        binary_array = np.random.rand(self.N) < self.probabilities[:,self.state]\n",
    "        \n",
    "        # Sample the next state from the transition probabilities\n",
    "        self.state = np.random.choice(self.D, p=self.transitions[self.state])\n",
    "        \n",
    "        return binary_array\n",
    "\n",
    "class Controlled_Flip_Generator:\n",
    "    def __init__(self, probabilities, transitions, state = 0):\n",
    "        \"\"\"\n",
    "        Initialize the flip generator.\n",
    "        :param probabilities: NxD numpy array of probabilities for generating binary vectors. N gives the number of coins/bits and D the number of system states\n",
    "        :param transitions: AxDxD numpy array representing state transition probabilities, where A is the size of an agents action space.\n",
    "        :param state: Integer representing the initial state.\n",
    "        \"\"\"\n",
    "        self.probabilities = probabilities\n",
    "        self.transitions = transitions\n",
    "        self.state = state\n",
    "        self.D, self.N = probabilities.shape  # Number of states (D) and vector length (N)\n",
    "        \n",
    "        # Assertions to ensure correct dimensionality\n",
    "        assert probabilities.shape[1] == transitions.shape[1], \"Probabilities and transitions must have the same number of states (D).\"\n",
    "    \n",
    "    def generate(self, action):\n",
    "        \"\"\"\n",
    "        Generate a binary vector based on the current state and transition probabilities.\n",
    "        :return: Generated binary array (1D numpy array of length N)\n",
    "        \"\"\"\n",
    "        self.state = np.random.choice(self.D, p=self.transitions[action,self.state,:])\n",
    "        # Generate a binary vector where each element is 1 with probability P_{i, j}\n",
    "        binary_array = np.random.rand(self.N) < self.probabilities[:,self.state]\n",
    "        \n",
    "        return binary_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
