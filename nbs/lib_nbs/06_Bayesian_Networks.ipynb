{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf0f067-1145-437b-8ecc-90a6844109c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp bayesianNetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a4683d-4d7d-4e50-9b9c-62e0091f8063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import projective_simulation.methods.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95657ecc-b873-43e5-b8be-bc7818affef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Bayesian_Network:\n",
    "    def __init__(self, num_sensory_elements, num_m_nodes, W_matrix, C_matrix, m_expectation = None):\n",
    "        self.num_sensory_elements = num_sensory_elements\n",
    "        self.num_m_nodes = num_m_nodes\n",
    "        self.W_matrix = W_matrix  # Shape: (num_sensory_elements, num_m_nodes)\n",
    "        self.C_matrix = C_matrix  # Shape: (num_m_nodes, num_m_nodes)\n",
    "        \n",
    "        # Initialize sensory and m-level variables as empty numpy arrays\n",
    "        self.sensory_excitation = np.empty(np.shape(W_matrix)[0])\n",
    "        self.m_excitation = np.empty(num_m_nodes)\n",
    "        self.m_expectation = np.full(num_m_nodes, fill_value = 1/num_m_nodes) if m_expectation is None else m_expectation\n",
    "        self.sensory_expectation = np.dot(self.m_expectation, self.W_matrix.T)\n",
    "        self.m_activation = np.empty(num_m_nodes)\n",
    "    \n",
    "    def excite_network(self, percept):\n",
    "        \"\"\"Set the sensory excitation and compute m_excitation.\"\"\"\n",
    "        if percept.shape[0] != self.num_sensory_elements:\n",
    "            raise ValueError(\"Percept vector size does not match the number of sensory elements.\")\n",
    "        \n",
    "        self.sensory_excitation = percept  # Set sensory excitation\n",
    "        \n",
    "        # Compute m_excitation using equation 1\n",
    "        self.m_excitation = np.prod(\n",
    "            np.power(self.W_matrix, self.sensory_excitation[:, np.newaxis]) * \n",
    "            np.power(1 - self.W_matrix, (1 - self.sensory_excitation)[:, np.newaxis]),\n",
    "            axis=0\n",
    "        )\n",
    "    \n",
    "    def activate(self):\n",
    "        \"\"\"Compute m_activation based on m_excitation and m_expectation.\"\"\"\n",
    "        numerator = self.m_excitation * self.m_expectation\n",
    "        denominator = np.sum(numerator)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            self.m_activation = np.zeros(self.num_m_nodes)  # Avoid division by zero (network properties are such that this should never happen)\n",
    "        else:\n",
    "            self.m_activation = numerator / denominator\n",
    "    \n",
    "    def set_expectations(self):\n",
    "        \"\"\"Set m_expectation and sensory_expectation based on activation and weight matrices.\"\"\"\n",
    "        \n",
    "        # Normalize C_matrix rows to ensure proper probability distributions\n",
    "        row_sums = self.C_matrix.sum(axis=1, keepdims=True)\n",
    "        normalized_C_matrix = np.divide(self.C_matrix, row_sums, where=row_sums!=0)\n",
    "        \n",
    "        # Compute m_expectation using the normalized C_matrix\n",
    "        self.m_expectation = np.dot(self.m_activation, normalized_C_matrix)\n",
    "        \n",
    "        # Compute sensory_expectation using W_matrix\n",
    "        self.sensory_expectation = transforms._shifted_exp(x = np.dot(self.m_expectation, self.W_matrix.T), k = 0)\n",
    "\n",
    "    def get_surprise(self):\n",
    "        \"\"\"Compute the total surprise of the network.\"\"\"\n",
    "        \n",
    "        # Compute individual sensory surprise values\n",
    "        surprise_values = np.where(\n",
    "            self.sensory_excitation == 1,\n",
    "            -np.log2(self.sensory_expectation),\n",
    "            -np.log2(1 - self.sensory_expectation)\n",
    "        )\n",
    "        \n",
    "        # Sum all sensory surprises to get total surprise\n",
    "        total_surprise = np.sum(surprise_values)\n",
    "        \n",
    "        return total_surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5306896c-6db9-4cbf-b482-1548813f73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Bayesian_Memory(Bayesian_Network):\n",
    "    def __init__(self, num_sensory_elements, num_m_nodes, W_matrix=None, C_matrix=None, timer=0, sensory_evidence_prior = 1, continuity_prior = 0.95):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian Memory network.\n",
    "        :param num_sensory_elements: Number of sensory elements.\n",
    "        :param num_m_nodes: Number of memory nodes.\n",
    "        :param W_matrix: Sensory to memory weight matrix, defaults to 0.5 for all weights if None.\n",
    "        :param C_matrix: Memory transition matrix, defaults to zeros if None.\n",
    "        :param timer: Integer tracking memory time index, defaults to 0.\n",
    "        \"\"\"\n",
    "        if W_matrix is None:\n",
    "            W_matrix = np.full((num_sensory_elements, num_m_nodes), fill_value = 0.5)\n",
    "        if C_matrix is None:\n",
    "            C_matrix = np.zeros((num_m_nodes, num_m_nodes))\n",
    "        \n",
    "        super().__init__(num_sensory_elements, num_m_nodes, W_matrix, C_matrix)\n",
    "        self.timer = timer\n",
    "        self.sensory_evidence_prior = sensory_evidence_prior\n",
    "        self.continuity_prior = continuity_prior\n",
    "    \n",
    "    def encode_memory(self):\n",
    "        \"\"\"Modify W_matrix and C_matrix to encode sensory input into memory.\"\"\"\n",
    "        \n",
    "        # Update W_matrix based on sensory excitation\n",
    "        self.W_matrix[:, self.timer] = self.sensory_excitation \n",
    "        \n",
    "        # Update C_matrix based on memory trace\n",
    "        trace = self.timer\n",
    "        self.C_matrix[:, trace] = (1 - self.continuity_prior) / (self.num_m_nodes - 1) #keeps wieghts normalized by default\n",
    "        self.C_matrix[trace - 1, trace] = self.continuity_prior\n",
    "\n",
    "        #remove excitation from encoded trace\n",
    "        self.m_excitation[trace] = 0\n",
    "\n",
    "        self.timer = (self.timer + 1) % self.num_m_nodes\n",
    "\n",
    "    def excite_network(self, percept):\n",
    "        \"\"\"Set the sensory excitation and compute m_excitation.\"\"\"\n",
    "        if percept.shape[0] != np.shape(self.W_matrix)[0]:\n",
    "            raise ValueError(\"Percept vector size does not match the number of sensory elements.\")\n",
    "        \n",
    "        self.sensory_excitation = percept  # Set sensory excitation\n",
    "\n",
    "        weighted_evidence = transforms._logistic(self.W_matrix, x_shift = 0.5, k = self.sensory_evidence_prior)\n",
    "        # Compute m_excitation using equation 1\n",
    "        self.m_excitation = np.prod(\n",
    "            np.power(weighted_evidence, self.sensory_excitation[:, np.newaxis]) *  #changed from the Bayesian Network to apply logistic function\n",
    "            np.power(1 - weighted_evidence, (1 - self.sensory_excitation)[:, np.newaxis]),\n",
    "            axis=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf5cdd3-e15a-46c6-ba27-c85e1be702c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Active_Inference_Memory(Bayesian_Memory):\n",
    "    def __init__(self, \n",
    "                 num_sensory_elements,\n",
    "                 num_action_elements, \n",
    "                 num_m_nodes,\n",
    "                 intrinsic_expectations = None,\n",
    "                 W_matrix=None, \n",
    "                 C_matrix=None,\n",
    "                 epsilon = 0.0001,\n",
    "                 timer=0, \n",
    "                 sensory_evidence_prior = 1, \n",
    "                 continuity_prior = 0.95):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian Memory network.\n",
    "        :param num_sensory_elements: Number of sensory elements.\n",
    "        :param num_m_nodes: Number of memory nodes.\n",
    "        :param num_action_elements: number of action elements\n",
    "        :param W_matrix: Sensory to memory weight matrix, defaults to 0.5 for all weights if None.\n",
    "        :param C_matrix: Memory transition matrix, defaults to zeros if None.\n",
    "        :param timer: Integer tracking memory time index, defaults to 0.\n",
    "        \"\"\"\n",
    "        if intrinsic_expectations is None:\n",
    "            self.intrinsic_expectations = np.zeros(num_sensory_elements)\n",
    "        else:\n",
    "            if not len(intrinsic_expectations) == num_sensory_elements:\n",
    "                raise ValueError(\"Intrinsic Expectations must be a 1D vector with length equal to the number of sensory elements\")\n",
    "            self.intrinsic_expectations = intrinsic_expectations\n",
    "        #create W Matrix with rows for both plain sensory elements and active sensory elements\n",
    "        #because other sensory variables are intialized from this matrix, this is all that is needed\n",
    "        if W_matrix is None:\n",
    "            W_matrix = np.full((num_sensory_elements + num_action_elements, num_m_nodes), fill_value = 0.5)\n",
    "            \n",
    "        super().__init__(num_sensory_elements, num_m_nodes, W_matrix, C_matrix, timer, sensory_evidence_prior, continuity_prior)\n",
    "        \n",
    "        #add action elements to sensory variables\n",
    "        self.num_action_elements = num_action_elements\n",
    "        self.action_encoder = np.append(np.zeros(num_sensory_elements), np.ones(num_action_elements)).astype('int') #tracks which sensory elements are actions\n",
    "\n",
    "        #create a vector for memory valences, to which system surprise is encoded\n",
    "        self.memory_valences = np.full(num_m_nodes, fill_value = np.nan)\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def encode_memory(self):\n",
    "        \"\"\"Modify W_matrix, C_matrix, and memory valences to encode sensory input into memory.\"\"\"\n",
    "        self.memory_valences[self.timer-1] = self.get_surprise()\n",
    "        super().encode_memory()\n",
    "\n",
    "    def set_expectations(self):\n",
    "        \"\"\"Set m_expectation and sensory_expectation based on activation, valence, and weight matrices.\"\"\"\n",
    "        \n",
    "        # Normalize C_matrix rows to ensure proper probability distributions\n",
    "        row_sums = self.C_matrix.sum(axis=1, keepdims=True)\n",
    "        normalized_C_matrix = np.divide(self.C_matrix, row_sums, where=row_sums!=0)\n",
    "        \n",
    "        # Compute m_expectation using the normalized C_matrix\n",
    "        self.m_expectation = np.dot(self.m_activation, normalized_C_matrix)\n",
    "        \n",
    "        # Compute weight adjustments based on suprise advantage and action encoder\n",
    "        priming = np.log(np.nanmean(self.memory_valences)/self.memory_valences)  #used to scale priming of active sensory elements as a function of trace valence\n",
    "        priming[np.isnan(priming)] = 0 #traces without valence do not prime (including current trace)\n",
    "        adjusted_weights = np.power(priming[:,np.newaxis], self.action_encoder) * self.W_matrix.T #multiplies weights to active sensory elements by memory trace suprise advantage (and weight to regular sensory elements by 1)\n",
    "        self.sensory_expectation = np.dot(self.m_expectation, adjusted_weights)\n",
    "        #adjust expectation based on intrinsic expectations\n",
    "        #note that this code depends on all plain sensory elements preceding all action representations in the action encoder \n",
    "        self.sensory_expectation = np.array([self.sensory_expectation[i] if self.action_encoder[i] == 1 else transforms._shifted_exp(self.sensory_expectation[i], k = self.intrinsic_expectations[i], epsilon = self.epsilon) for i in range(len(self.sensory_expectation))])\n",
    "\n",
    "    def get_surprise(self):\n",
    "        \"\"\"Compute the total surprise of the network.\"\"\"\n",
    "        notaction_encoder = [not action for action in self.action_encoder.astype('bool')]\n",
    "        plain_sensory_excitation = self.sensory_excitation[notaction_encoder]\n",
    "        # Compute individual sensory surprise values\n",
    "        surprise_values = np.where(\n",
    "            plain_sensory_excitation == 1,\n",
    "            -np.log2(self.sensory_expectation[notaction_encoder]),\n",
    "            -np.log2(1 - self.sensory_expectation[notaction_encoder])\n",
    "        )\n",
    "        \n",
    "        # Sum all sensory surprises to get total surprise\n",
    "        total_surprise = np.sum(surprise_values)\n",
    "        \n",
    "        return total_surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b5a83f0-a8ee-4faa-9e12-5ec89beccbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SiPS_ECM(Active_Inference_Memory):\n",
    "    def __init__(self, \n",
    "                 num_sensory_elements,\n",
    "                 num_action_elements, \n",
    "                 num_m_nodes,\n",
    "                 intrinsic_expectations = None,\n",
    "                 W_matrix=None, \n",
    "                 C_matrix=None,\n",
    "                 H_matrix = None,\n",
    "                 h_damp = 0.01,\n",
    "                 glow_damp = 1,\n",
    "                 epsilon = 0.0001,\n",
    "                 timer=0, \n",
    "                 sensory_evidence_prior = 1, \n",
    "                 continuity_prior = 0.95,\n",
    "                 deliberation_length: int = 1,\n",
    "                 learning_influence = 1\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian Memory network.\n",
    "        :param num_sensory_elements: Number of sensory elements.\n",
    "        :param num_m_nodes: Number of memory nodes.\n",
    "        :param num_action_elements: number of action elements\n",
    "        :param W_matrix: Sensory to memory weight matrix, defaults to 0.5 for all weights if None.\n",
    "        :param C_matrix: Memory transition matrix, defaults to zeros if None.\n",
    "        :param timer: Integer tracking memory time index, defaults to 0.\n",
    "        \"\"\"\n",
    "        super().__init__(num_sensory_elements,\n",
    "                 num_action_elements, \n",
    "                 num_m_nodes,\n",
    "                 intrinsic_expectations,\n",
    "                 W_matrix, \n",
    "                 C_matrix,\n",
    "                 epsilon,\n",
    "                 timer, \n",
    "                 sensory_evidence_prior, \n",
    "                 continuity_prior)\n",
    "        self.H_matrix = np.zeros((num_m_nodes, num_m_nodes)) if H_matrix is None else H_matrix\n",
    "        self.H_glow = np.zeros((num_m_nodes, num_m_nodes))\n",
    "        self.deliberation_length = deliberation_length\n",
    "        self.h_damp = h_damp\n",
    "        self.glow_damp = glow_damp\n",
    "        self.learning_influence = learning_influence\n",
    "\n",
    "    def activate(self):\n",
    "        self.m_activation = [0 for _ in self.m_activation]\n",
    "        position = self.timer\n",
    "        for tau in range(self.deliberation_length):\n",
    "            scaled_H = self.H_matrix[position,:] - np.mean(self.H_matrix[position:]) #scale to avoid large numbers. Use the mean because large positive numbers are more likely than large negative numbers (positive edge weights can get used and reinforced repeatedly) \n",
    "            projection_weights = np.exp(self.learning_influence * scaled_H) * self.m_excitation * self.m_expectation\n",
    "            projection_probs = projection_weights/np.sum(projection_weights)\n",
    "            new_position = np.random.choice(range(len(projection_probs)), p = projection_probs)\n",
    "            self.H_glow[position,new_position] += 1/self.deliberation_length\n",
    "            position = new_position\n",
    "            self.m_activation[position] = 1\n",
    "        self.m_activation = self.m_activation/np.sum(self.m_activation)\n",
    "\n",
    "    def deliberate(self,percept):\n",
    "        self.excite_network(percept)\n",
    "        self.encode_memory()\n",
    "        self.update()\n",
    "        self.activate()\n",
    "        self.set_expectations()\n",
    "\n",
    "    def update(self):\n",
    "        self.H_matrix = self.H_matrix - self.h_damp * self.H_matrix #return H_matrix weights toward baselinge (presumed to be zero)\n",
    "        self.H_matrix = self.H_matrix + self.H_glow * np.log(np.nanmean(self.memory_valences)/self.get_surprise()) #reinforce H_matrix weights for edges used to deliberate as a function of surprise advantage\n",
    "        self.H_glow = self.H_glow - self.glow_damp * self.H_glow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9f7e2444-80df-4aec-86f8-2c98a5877216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "[0.     0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n"
     ]
    }
   ],
   "source": [
    "test_SiPS = SiPS_ECM(num_sensory_elements = 2,\n",
    "                     num_action_elements = 2,\n",
    "                     num_m_nodes = 50,\n",
    "                     continuity_prior = 0.5,\n",
    "                     sensory_evidence_prior = 3,\n",
    "                     deliberation_length = 5,\n",
    "                    ) \n",
    "\n",
    "print(test_SiPS.m_expectation)\n",
    "test_SiPS.deliberate(np.array((0,1,0,1)))\n",
    "print(test_SiPS.m_excitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70ae0cce-0fc3-4658-a9de-3d7723649085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation\n",
      "[0.  0.  0.  0.2 0.  0.  0.2 0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]\n",
      "expectation\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('activation')\n",
    "print(test_SiPS.m_activation)\n",
    "print('expectation')\n",
    "print(test_SiPS.m_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17e4479b-f5f9-4e21-b145-db599d9b18f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44679602 0.         0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625    ]\n"
     ]
    }
   ],
   "source": [
    "test_SiPS.deliberate(np.array((0,1,0,1)))\n",
    "print(test_SiPS.m_excitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3efc0070-2d89-41f9-b98c-fd9976bc43eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "expectation\n",
      "[0.02 0.98 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "print('activation')\n",
    "print(test_SiPS.m_activation)\n",
    "print('expectation')\n",
    "print(test_SiPS.m_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cbac40fb-81fb-4a17-a5f2-1bf9ed7b20ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excitation\n",
      "[0.44679602 0.44679602 0.         0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625    ]\n",
      "activation\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "expectation\n",
      "[0.01960784 0.01960784 0.96078431 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "test_SiPS.deliberate(np.array((0,1,0,1)))\n",
    "print('excitation')\n",
    "print(test_SiPS.m_excitation)\n",
    "print('activation')\n",
    "print(test_SiPS.m_activation)\n",
    "print('expectation')\n",
    "print(test_SiPS.m_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28d69f57-7ed2-454f-803c-47304caf6e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.98261442,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 7.7456536 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_SiPS.H_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "62fabb44-02f8-421e-bf16-69e14331c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excitation\n",
      "[0.44679602 0.44679602 0.44679602 0.         0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625    ]\n",
      "activation\n",
      "[0.5 0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "expectation\n",
      "[0.01923077 0.48076923 0.01923077 0.48076923 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "test_SiPS.deliberate(np.array((0,1,0,1)))\n",
    "print('excitation')\n",
    "print(test_SiPS.m_excitation)\n",
    "print('activation')\n",
    "print(test_SiPS.m_activation)\n",
    "print('expectation')\n",
    "print(test_SiPS.m_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0ec8fc7-6a6f-413e-a424-ce42fc6614e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.67278827,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , 29.83246291,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 7.66819707,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_SiPS.H_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c31e63e-8b19-4d83-b581-b0495cdc9113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excitation\n",
      "[0.02224466 0.02224466 0.02224466 0.02224466 0.         0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625    ]\n",
      "activation\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "expectation\n",
      "[0.01886792 0.01886792 0.9245283  0.01886792 0.01886792 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "test_SiPS.deliberate(np.array((1,0,0,1)))\n",
    "print('excitation')\n",
    "print(test_SiPS.m_excitation)\n",
    "print('activation')\n",
    "print(test_SiPS.m_activation)\n",
    "print('expectation')\n",
    "print(test_SiPS.m_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dd809567-ed9c-444f-aac3-38d2f8d7cb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excitation\n",
      "[0.02224466 0.02224466 0.02224466 0.02224466 0.44679602 0.\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625    ]\n",
      "activation\n",
      "[0.5 0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "expectation\n",
      "[0.01851852 0.46296296 0.01851852 0.46296296 0.01851852 0.01851852\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "test_SiPS.deliberate(np.array((1,0,0,1)))\n",
    "print('excitation')\n",
    "print(test_SiPS.m_excitation)\n",
    "print('activation')\n",
    "print(test_SiPS.m_activation)\n",
    "print('expectation')\n",
    "print(test_SiPS.m_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e344100-89d0-4784-9463-d3457b5c1623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excitation\n",
      "[0.44679602 0.44679602 0.44679602 0.44679602 0.02224466 0.02224466\n",
      " 0.         0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625    ]\n",
      "activation\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "expectation\n",
      "[0.01818182 0.01818182 0.89090909 0.01818182 0.01818182 0.01818182\n",
      " 0.01818182 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "test_SiPS.deliberate(np.array((0,1,0,1)))\n",
    "print('excitation')\n",
    "print(test_SiPS.m_excitation)\n",
    "print('activation')\n",
    "print(test_SiPS.m_activation)\n",
    "print('expectation')\n",
    "print(test_SiPS.m_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde11a5-a119-4372-8cb4-0450483b7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Basic_Agent():\n",
    "    def __init__(self,active_inference_memory, action_softmax_temp = 1):\n",
    "        self.memory_network = active_inference_memory\n",
    "        self.num_actions = active_inference_memory.num_action_elements\n",
    "        self.action = None\n",
    "        self.action_softmax_temp = action_softmax_temp\n",
    "\n",
    "    def get_action(self):\n",
    "        '''\n",
    "        choose an action based on expectations of memory network set in previous step\n",
    "        '''\n",
    "        primes = self.memory_network.sensory_expectation[self.memory_network.action_encoder.astype('bool')]\n",
    "        primes_softmax = transforms._softmax(self.action_softmax_temp,primes) #use softmax to nomormalize over real values and get probabilities\n",
    "        self.action = np.random.choice(self.num_actions, p = primes_softmax)\n",
    "        return(self.action)\n",
    "\n",
    "    def deliberate(self,observation):\n",
    "        '''\n",
    "        evaluate current state and make predictions\n",
    "        '''\n",
    "        action_representation = np.zeros(self.num_actions)\n",
    "        action_representation[self.action] = 1\n",
    "        percept = np.append(observation, action_representation)\n",
    "        self.memory_network.excite_network(percept)\n",
    "        self.memory_network.encode_memory()\n",
    "        self.memory_network.activate()\n",
    "        self.memory_network.set_expectations()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802c3fc-b30d-41f8-a2eb-359e3d059219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Flip_Generator:\n",
    "    def __init__(self, probabilities, transitions, state):\n",
    "        \"\"\"\n",
    "        Initialize the flip generator.\n",
    "        :param probabilities: NxD numpy array of probabilities for generating binary vectors. N gives the number of coins/bits and D the number of system states\n",
    "        :param transitions: DxD numpy array representing state transition probabilities.\n",
    "        :param state: Integer representing the initial state.\n",
    "        \"\"\"\n",
    "        self.probabilities = probabilities\n",
    "        self.transitions = transitions\n",
    "        self.state = state\n",
    "        self.D, self.N = probabilities.shape  # Number of states (D) and vector length (N)\n",
    "        \n",
    "        # Assertions to ensure correct dimensionality\n",
    "        assert transitions.shape == (self.D, self.D), \"Transitions matrix must be DxD.\"\n",
    "        assert probabilities.shape[1] == transitions.shape[1], \"Probabilities and transitions must have the same number of states (D).\"\n",
    "        assert np.allclose(transitions.sum(axis=1), 1), \"Each row of the transition matrix must sum to 1.\"\n",
    "    \n",
    "    def generate(self):\n",
    "        \"\"\"\n",
    "        Generate a binary vector based on the current state and transition probabilities.\n",
    "        :return: Generated binary array (1D numpy array of length N)\n",
    "        \"\"\"\n",
    "        # Generate a binary vector where each element is 1 with probability P_{i, j}\n",
    "        binary_array = np.random.rand(self.N) < self.probabilities[:,self.state]\n",
    "        \n",
    "        # Sample the next state from the transition probabilities\n",
    "        self.state = np.random.choice(self.D, p=self.transitions[self.state])\n",
    "        \n",
    "        return binary_array\n",
    "\n",
    "class Controlled_Flip_Generator:\n",
    "    def __init__(self, probabilities, transitions, state = 0):\n",
    "        \"\"\"\n",
    "        Initialize the flip generator.\n",
    "        :param probabilities: NxD numpy array of probabilities for generating binary vectors. N gives the number of coins/bits and D the number of system states\n",
    "        :param transitions: AxDxD numpy array representing state transition probabilities, where A is the size of an agents action space.\n",
    "        :param state: Integer representing the initial state.\n",
    "        \"\"\"\n",
    "        self.probabilities = probabilities\n",
    "        self.transitions = transitions\n",
    "        self.state = state\n",
    "        self.D, self.N = probabilities.shape  # Number of states (D) and vector length (N)\n",
    "        \n",
    "        # Assertions to ensure correct dimensionality\n",
    "        assert probabilities.shape[1] == transitions.shape[1], \"Probabilities and transitions must have the same number of states (D).\"\n",
    "    \n",
    "    def generate(self, action):\n",
    "        \"\"\"\n",
    "        Generate a binary vector based on the current state and transition probabilities.\n",
    "        :return: Generated binary array (1D numpy array of length N)\n",
    "        \"\"\"\n",
    "        self.state = np.random.choice(self.D, p=self.transitions[action,self.state,:])\n",
    "        # Generate a binary vector where each element is 1 with probability P_{i, j}\n",
    "        binary_array = np.random.rand(self.N) < self.probabilities[:,self.state]\n",
    "        \n",
    "        return binary_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
