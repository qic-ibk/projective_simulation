{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b355a51-6ded-4f9e-9edf-576e6b2cccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp basic_PS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784f52d-f60c-4bc8-80d2-b82ebae3b877",
   "metadata": {},
   "source": [
    "# Basic PS\n",
    "> This notebook gathers the most basic implementation of PS\n",
    "\n",
    "(currently copy pasted from [here](https://github.com/HendrikPN/rl-ion-trap-tutorial/blob/master/ps.py))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d62e94-f496-4378-ae6c-2f5d1e83bb36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class PSAgent(object):\n",
    "    def __init__(self, \n",
    "                 num_actions: int, # The number of available actions.\n",
    "                 glow: float = 0.1, # The glow (or eta) parameter. \n",
    "                 damp: float = 0., # The damping (or gamma) parameter. \n",
    "                 softmax: float = 0.1 # The softmax (or beta) parameter. \n",
    "                ):\n",
    "        \"\"\"\n",
    "        Simple, 2-layered projective simulation (PS) agent. We initialize an h-matrix with a single row of `num_actions` \n",
    "        entries corresponding to a dummy percept clip being connected to all possible actions with h-values of all 1. We \n",
    "        initialize a g-matrix with a single row of `num_actions` entries with all 0s corresponding to the *glow* values \n",
    "        of percept-action transitions.\n",
    "                      \n",
    "        NOTE: This simple version misses some features such as clip deletion, emotion tags or generalization mechanisms.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.num_actions = num_actions\n",
    "        self.glow = glow\n",
    "        self.damp = damp\n",
    "        self.softmax = softmax\n",
    "        #int: current number of percepts.\n",
    "        self.num_percepts = 0\n",
    "        #np.ndarray: h-matrix with current h-values. Defaults to all 1.\n",
    "        self.hmatrix = np.ones([1,self.num_actions])\n",
    "        #np.ndarray: g-matrix with current glow values. Defaults to all 0.\n",
    "        self.gmatrix = np.zeros([1,self.num_actions])\n",
    "        #dict: Dictionary of percepts as {\"percept\": index}\n",
    "        self.percepts = {}\n",
    "        \n",
    "    def predict(self, \n",
    "                observation: object # A percept in form of an object.\n",
    "               )-> int : # The action to be performed.\n",
    "        \"\"\"\n",
    "        Given an observation, returns an action.\n",
    "        (1) Create a percept from an observation.\n",
    "        (2) Add percept if it has not been encountered before.\n",
    "        (3) Get action from h-values.\n",
    "        (4) Update g-matrix.\n",
    "        \"\"\"\n",
    "        # (1) create percept from observation\n",
    "        percept = self._get_percept(observation)\n",
    "        # (2) add percept to clip network if it has not been encountered before\n",
    "        if percept not in self.percepts.keys():\n",
    "            # add new percept\n",
    "            self.percepts[percept] = self.num_percepts\n",
    "            # increment number of percepts\n",
    "            self.num_percepts += 1\n",
    "            # add column to h-matrix\n",
    "            self.hmatrix = np.append(self.hmatrix, \n",
    "                                     np.ones([1,self.num_actions]),\n",
    "                                     axis=0)\n",
    "            # add column to g-matrix\n",
    "            self.gmatrix = np.append(self.gmatrix, \n",
    "                                     np.zeros([1,self.num_actions]),\n",
    "                                     axis=0)\n",
    "        \n",
    "        # (3) get action from h-value\n",
    "        # get index from dictionary entry\n",
    "        percept_index = self.percepts[percept]\n",
    "        # get h-values\n",
    "        h_values = self.hmatrix[percept_index]\n",
    "        # get probabilities from h-values through a softmax function\n",
    "        prob = self._softmax(h_values)\n",
    "        # get action\n",
    "        action = np.random.choice(range(self.num_actions), p=prob)\n",
    "        \n",
    "        # (4) update g-matrix\n",
    "        self.gmatrix[int(percept_index),int(action)] = 1.\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train(self, reward):\n",
    "        \"\"\"\n",
    "        Given a reward, updates h-matrix. Updates g-matrix with glow.\n",
    "        \"\"\"\n",
    "        # damping h-matrix\n",
    "        self.hmatrix = self.hmatrix - self.damp*(self.hmatrix-1.)\n",
    "        # update h-matrix\n",
    "        self.hmatrix += reward*self.gmatrix\n",
    "        # update g-matrix\n",
    "        self.gmatrix = (1-self.glow)*self.gmatrix\n",
    "    \n",
    "    # ----------------- helper methods -----------------------------------------\n",
    "\n",
    "    def _get_percept(self, observation):\n",
    "        \"\"\"\n",
    "        Given an observation, returns a percept.\n",
    "        This function is just to emphasize the difference between observations\n",
    "        issued by the environment and percepts which describe the observations\n",
    "        as perceived by the agent.\n",
    "        \"\"\"\n",
    "        percept = str(observation)\n",
    "        return percept\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        \"\"\"\n",
    "        Given an input, calculates the normalized exponential function.\n",
    "        \"\"\"\n",
    "        # rescale exponential to avoid large numbers\n",
    "        rescale = max(x)\n",
    "        exp_x = np.exp(self.softmax*(x-rescale))\n",
    "        # get normalization\n",
    "        norm = sum(exp_x)\n",
    "        # calculate normalized exponential\n",
    "        softmax_x = exp_x/norm\n",
    "\n",
    "        return softmax_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e79e6-231d-4156-8b40-4eaa9df86bee",
   "metadata": {},
   "source": [
    "## Properly documenting your functions\n",
    "\n",
    "In the class above you will see the preferred way of documenting your code (I have only done so for the main class and the funcion `predict`. It is based in [`docments`](https://fastcore.fast.ai/docments.html). As you will see, this translates directly into a nice webpage documentation. Nonetheless, [`sphynx`](https://www.sphinx-doc.org/en/master/usage/extensions/example_numpy.html) type documentation is also supported (and helpful when having very long descriptions).\n",
    "\n",
    "To see how the documentation will look like, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90053a4f-4baf-4038-9442-399d52ed2aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fccfa7f1-ad52-49ab-9e83-6a3e7123c1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/{user}/projective_simulation/blob/master/projective_simulation/basic_PS.py#L9){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PSAgent\n",
       "\n",
       ">      PSAgent (num_actions:int, glow:float=0.1, damp:float=0.0,\n",
       ">               softmax:float=0.1)\n",
       "\n",
       "Simple, 2-layered projective simulation (PS) agent. We initialize an h-matrix with a single row of `num_actions` \n",
       "entries corresponding to a dummy percept clip being connected to all possible actions with h-values of all 1. We \n",
       "initialize a g-matrix with a single row of `num_actions` entries with all 0s corresponding to the *glow* values \n",
       "of percept-action transitions.\n",
       "\n",
       "NOTE: This simple version misses some features such as clip deletion, emotion tags or generalization mechanisms.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| num_actions | int |  | The number of available actions. |\n",
       "| glow | float | 0.1 | The glow (or eta) parameter. |\n",
       "| damp | float | 0.0 | The damping (or gamma) parameter. |\n",
       "| softmax | float | 0.1 | The softmax (or beta) parameter. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/{user}/projective_simulation/blob/master/projective_simulation/basic_PS.py#L9){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PSAgent\n",
       "\n",
       ">      PSAgent (num_actions:int, glow:float=0.1, damp:float=0.0,\n",
       ">               softmax:float=0.1)\n",
       "\n",
       "Simple, 2-layered projective simulation (PS) agent. We initialize an h-matrix with a single row of `num_actions` \n",
       "entries corresponding to a dummy percept clip being connected to all possible actions with h-values of all 1. We \n",
       "initialize a g-matrix with a single row of `num_actions` entries with all 0s corresponding to the *glow* values \n",
       "of percept-action transitions.\n",
       "\n",
       "NOTE: This simple version misses some features such as clip deletion, emotion tags or generalization mechanisms.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| num_actions | int |  | The number of available actions. |\n",
       "| glow | float | 0.1 | The glow (or eta) parameter. |\n",
       "| damp | float | 0.0 | The damping (or gamma) parameter. |\n",
       "| softmax | float | 0.1 | The softmax (or beta) parameter. |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PSAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc9823-ccea-4e45-b823-e70ca9aee5fc",
   "metadata": {},
   "source": [
    "When creating the webpage documentation, `nbdev` will put there whatever does not have `#| hide`. Moreover, it will also put all the `show_doc` it finds within tghe notebooks. Sometimes, you want to hide the doc from a class, but show instead the documenation of a particular function. To do this, put `#| hide` in the corresponding cell and then use `show_doc` of the desired function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a4feb4-06d7-440b-bf83-0ac842c7a0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/{user}/projective_simulation/blob/master/projective_simulation/basic_PS.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### predict\n",
       "\n",
       ">      predict (observation:object)\n",
       "\n",
       "Given an observation, returns an action.\n",
       "(1) Create a percept from an observation.\n",
       "(2) Add percept if it has not been encountered before.\n",
       "(3) Get action from h-values.\n",
       "(4) Update g-matrix.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| observation | object | A percept in form of an object. |\n",
       "| **Returns** | **int** | **The action to be performed.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/{user}/projective_simulation/blob/master/projective_simulation/basic_PS.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### predict\n",
       "\n",
       ">      predict (observation:object)\n",
       "\n",
       "Given an observation, returns an action.\n",
       "(1) Create a percept from an observation.\n",
       "(2) Add percept if it has not been encountered before.\n",
       "(3) Get action from h-values.\n",
       "(4) Update g-matrix.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| observation | object | A percept in form of an object. |\n",
       "| **Returns** | **int** | **The action to be performed.** |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PSAgent.predict, name = 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8686e5-8809-4554-97eb-06507b85c25e",
   "metadata": {},
   "source": [
    "## A nice example\n",
    "\n",
    "Aside of full explanations given in the tutorials, it is also nice to include some examples of use after defining a class/function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35955b40-78f0-41e9-ab19-1a033fba7fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_actions = 5\n",
    "agent = PSAgent(num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f69e4e4-5579-4223-a214-0c89e3824a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PSAgent at 0x7fd8c1f31810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PS_repo",
   "language": "python",
   "name": "ps_repo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
