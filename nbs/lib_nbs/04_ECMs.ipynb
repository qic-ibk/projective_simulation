{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c27c4-41b7-4367-814f-1ac318d674fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ECMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df46e8b-c2dd-4562-bb9d-e49695f41899",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2aca4-b29e-4e99-9880-1f509f2d8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import projective_simulation.methods.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5475b4-a17f-44f1-ba9c-3ace43286a47",
   "metadata": {},
   "source": [
    "# Abstract ECM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbeb219-d8ac-427c-8d02-868a3c884b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Abstract_ECM(ABC):\n",
    "    \"\"\"A minimal ECM, every agent should be Derived from this class. Primarily serves to enforce that all ECMs have the \"ECM\" class\n",
    "\n",
    "    Examples:\n",
    "    >>> pass\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_actions: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ECM: The ECM Object to use\n",
    "            percept_processor: An optional object for transforming observations prior to passing to ECM as a percept. Must have method \"preprocess\"\n",
    "            action_processor: An optional object for transforming actions prior to passing to Environment as an actuator state. Must have method \"postprocess\"            \n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def deliberate(self, percept: str):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            percept: A string corresponding to an existing or new (will be added) key in the ECM percept dictionary\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93a56c-8778-4f41-93c7-6e917f669250",
   "metadata": {},
   "source": [
    "# Two Layer ECMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97738bf4-5dc1-4b6d-b893-c9057675e02f",
   "metadata": {},
   "source": [
    "## Basic Two Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deeec79-d8e1-451f-a275-c01f306a184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Two_Layer(Abstract_ECM):\n",
    "    def __init__(self, \n",
    "                 num_actions: int, # The number of available actions.\n",
    "                 glow: float, # The glow (or eta) parameter. \n",
    "                 damp: float, # The damping (or gamma) parameter. \n",
    "                 softmax: float # The softmax (or beta) parameter.\n",
    "                ):        \n",
    "        \"\"\"\n",
    "        Simple, 2-layered ECM. We initialize an h-matrix with a single row of `num_actions` \n",
    "        entries corresponding to a dummy percept clip being connected to all possible actions with h-values of all 1. We \n",
    "        initialize a g-matrix with a single row of `num_actions` entries with all 0s corresponding to the *glow* values \n",
    "        of percept-action transitions.\n",
    "\n",
    "        Percepts must be created from new observations with a preprocessor, e.g. add_percepts\n",
    "                      \n",
    "        NOTE: This simple version misses some features such as clip deletion, emotion tags or generalization mechanisms.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.num_actions = num_actions\n",
    "        self.glow = glow\n",
    "        self.damp = damp\n",
    "        self.softmax = softmax\n",
    "        #int: current number of percepts.\n",
    "        self.num_percepts = 0\n",
    "        #np.ndarray: h-matrix with current h-values. Defaults to all 1.\n",
    "        self.hmatrix = np.ones([1,self.num_actions])\n",
    "        #np.ndarray: g-matrix with current glow values. Defaults to all 0.\n",
    "        self.gmatrix = np.zeros([1,self.num_actions])\n",
    "        #dict: Dictionary of percepts as {\"percept\": index}\n",
    "        self.percepts = {}\n",
    "\n",
    "    def deliberate(self, percept: str):\n",
    "        \"\"\"\n",
    "        Given a percept, returns an action and changes the ECM if necessary\n",
    "        First, if the percept is new, it will be added to the ECM\n",
    "        Then, an action is selected as a function of the percept and the h-values of edges connected to that percept\n",
    "        Finally, the g-matrix is updated based on the realized percept-action pair.\n",
    "        \"\"\"\n",
    "        #Add percept to ECM if not already present\n",
    "        self.add_percept(percept)\n",
    "        #Perform Random Walk\n",
    "        # get index from dictionary entry\n",
    "        percept_index = self.percepts[percept]\n",
    "        # get h-values\n",
    "        h_values = self.hmatrix[percept_index]\n",
    "        # get probabilities from h-values through a softmax function\n",
    "        prob = transforms._softmax(self.softmax, h_values)\n",
    "        # get action\n",
    "        action = np.random.choice(range(self.num_actions), p=prob)        \n",
    "        #pdate g-matrix\n",
    "        self.gmatrix[int(percept_index),int(action)] = 1.\n",
    "        return action\n",
    "\n",
    "    def add_percept(self, percept):\n",
    "        '''\n",
    "        Checks if percept is in dictionary and adds to ECM in not\n",
    "        '''\n",
    "        if percept not in self.percepts.keys(): \n",
    "            self.percepts[percept] = self.num_percepts\n",
    "            # increment number of percepts\n",
    "            self.num_percepts += 1\n",
    "            # add column to h-matrix\n",
    "            self.hmatrix = np.append(self.hmatrix, \n",
    "                                     np.ones([1,self.num_actions]),\n",
    "                                     axis=0)\n",
    "            # add column to g-matrix\n",
    "            self.gmatrix = np.append(self.gmatrix, \n",
    "                                    np.zeros([1,self.num_actions]),\n",
    "                                    axis=0)\n",
    "\n",
    "    def learn(self, reward):\n",
    "        \"\"\"\n",
    "        Given a reward, updates h-matrix. Updates g-matrix with glow.\n",
    "        \"\"\"\n",
    "        # damping h-matrix\n",
    "        self.hmatrix = self.hmatrix - self.damp*(self.hmatrix-1.)\n",
    "        # update h-matrix\n",
    "        self.hmatrix += reward*self.gmatrix\n",
    "        # update g-matrix\n",
    "        self.gmatrix = (1-self.glow)*self.gmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f161bf-f152-47b7-a791-bcbcf5f8af3d",
   "metadata": {},
   "source": [
    "## Priming Two Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca43ac0-7080-4f63-9418-0bf032ce8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Priming_ECM(Two_Layer):\n",
    "    '''\n",
    "    This sub-class of the Two-Layer ECM adds a variable for action priming.\n",
    "    This variable should be a list of floats, each element of which corresponds to an action in the ECM.\n",
    "    These \"priming values\" are summed with h-values of any edge connected to the associated action node prior to calculating walk probabilites with the softmax function\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 num_actions: int, # The number of available actions.                 \n",
    "                 glow: float = 0.1, # The glow (or eta) parameter. \n",
    "                 damp: float = 0.01, # The damping (or gamma) parameter. \n",
    "                 softmax: float = 0.5, # The softmax (or beta) parameter.\n",
    "                 action_primes: list = None, #weights on the probability that deliberation steps into each action. Defaults to 0 for each action \n",
    "                ):\n",
    "        if action_primes is None:\n",
    "            action_primes = [0.] * num_actions\n",
    "        assert len(action_primes) == num_actions\n",
    "        super().__init__(num_actions, glow, damp, softmax)\n",
    "        self.action_primes = action_primes\n",
    "        \n",
    "\n",
    "    def deliberate(self, percept):\n",
    "        '''\n",
    "        Almost identical to the deliberate function of Two-Layer parent class, but sums h-values and action primes prior to calculating walk probabilities\n",
    "        '''\n",
    "        self.add_percept(percept)\n",
    "        #Perform Random Walk\n",
    "        # get index from dictionary entry\n",
    "        percept_index = self.percepts[percept]\n",
    "        # get h-values\n",
    "        h_values = self.hmatrix[percept_index]\n",
    "        #~~~Differences from two-layer deliberate function within\n",
    "        assert len(h_values) == len (self.action_primes)\n",
    "        # get probabilities from h-values and primes through a softmax function\n",
    "        prob = transforms._softmax(self.softmax, h_values + self.action_primes)\n",
    "        #~~~~~~~\n",
    "        # get action\n",
    "        action = np.random.choice(range(self.num_actions), p=prob)        \n",
    "        #pdate g-matrix\n",
    "        self.gmatrix[int(percept_index),int(action)] = 1.\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5f245-9469-46d2-9163-77933555e13d",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3660f-8cbd-4852-bde9-d5adb33ef485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval : false\n",
    "from projective_simulation.environments import RLGL\n",
    "from projective_simulation.ECMs import Priming_ECM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_ECM = Priming_ECM(num_actions = 2, action_primes = [0., 1.5])\n",
    "#Number of steps to run simulation\n",
    "T = 100\n",
    "data_log = [None] * T\n",
    "env = RLGL() #create a default red-light-green-light environment\n",
    "\n",
    "for t in range(T):\n",
    "    observation = env.get_observation()\n",
    "    action = test_ECM.deliberate(observation)\n",
    "    reward = env.get_reward(action)\n",
    "    test_ECM.learn(reward)\n",
    "    data_log[t] = {\"env_state\": env.state, \"action\": action, \"reward\": reward}\n",
    "    env.transition(action)\n",
    "\n",
    "plt.plot(range(T), [np.mean([data_log[step][\"reward\"] for step in range(i-10,i+1) if step >= 0]) for i in range(T)]) #plot a 10 step moving average of the reward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7261164-245b-46a4-a4ef-98013993e8b0",
   "metadata": {},
   "source": [
    "## Episodic ECM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cffba1-70f3-496a-8a18-35a9b7be9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Episodic_Memory(Abstract_ECM):\n",
    "    def __init__(self,\n",
    "                 num_actions: int, # the number of perceptual representations available to the agent which, when excited, have an effect on the agent's environment. Action representations are primed differently than sensory representations and do not affect surprise\n",
    "                 capacity: int = 10, # the number of memory traces avaiable to the agent. If simulation time exceeds capacity, the oldest memory trace will be overwritten each time step\n",
    "                 softmax: float = 1, # used to determine random walk probabilities, edge weights are normalized using a softmax function with this variable as the temperature constant\n",
    "                 focus: float = 0., #Focus scales the effect of stochastic processes underlying random walks on the ECM. (i.e. it scales the effect of Projective Simulation)\n",
    "                                    #Think of deliberation in an Episodic ECM like a very large number of particles diffusing on the ECM graph, but at each node a single particle is chosen at random and some proportion of particles are pulled along with that one. Focus defines that proportion\n",
    "                                    #If focus == 1, deliberation acts as a random walk of a single (massive) particle on the ECM. \n",
    "                                    #If focus == 0, deliberation acts as the diffusion of a large (approaching infinite) number of particles on the ECM\n",
    "                 kappa: float = 1., #How strongly the agent discounts the similarity between two states per bit of mismatched sensory information when establishing a new belief state\n",
    "                 intrinsic_expectations: dict = None, #If a key in this dictionary corresponds to an index of the agent's perceptual representations, the items value will be added to that percepts expectation value during the agent's predictions. Agents will seek out states that excite perceptual representations with intrinsic expectation\n",
    "                 epsilon: float = 0.01,  # a baseline value for the priming of perceptual representations. Must be greater than 0 to prevent infinite surprise if a perceptual representation is excited that was not predicted by the agents belief state. Note this will be transormed by the logistic function, so entropy calculations are not done using precisely this number\n",
    "                 deliberation_length: int = 1,   # deliberation_length: the number of diffusive steps in the agent's deliberations\n",
    "                 t: int = 0, #used to model the temporal excitation sequence of memory traces\n",
    "                 expectation_scale: float = 3 #A logistic function is used to scale percept priming between zero and one. This default rate parameter keeps the function used approximately linear when the input is between 0.1 and 0.8\n",
    "                ):\n",
    "        '''\n",
    "        The episodic memory ECM stores percept information in a time ordered system of memory traces by establishing connections (trace_encoder) with weights (hmatrix) between excited perceptual representations and an excited memory trace.\n",
    "        The agent maintains a belief state through the activation (different from excitation) of memory traces, where the strength of activation reflects the strength of the agent's belief that its current state-in-the-world is effectively the same as a state-in-the-world represented by that memory trace\n",
    "        The agent also maintains an expectation state by priming perceptual representations as a function of (1) its belief state, (2) connections between memory traces (mmatrix, stricly time-ordered in this implementation), and (3) the h-matrix\n",
    "        The difference between the agent's expectation state and the excitation of perceptual represenations in the next time step is computed as a surprise and assigned to the last excited memory trace as a valence state\n",
    "        Perceptual representations are excited as a function of sensory-motor interactions with the world and the agent's expectation state\n",
    "        Memory Traces are excited in a time-ordered, winner-takes all fashion.\n",
    "        The agent's beliefs are updated by a process of deliberation, in which excited perceptual representations are activated and those activations then diffuse across the ECM as if they were caused by particles performing a random walk on the ECM graph\n",
    "        The probability that an activation particle walks from one node to another is a function of the edge weights in the hmatrix connected to its current node (perceptual representation or memory trace), and the belief states and valence states of all nodes to which those edges lead\n",
    "        The focus parameter of the Episodic ECM adds weight to a single departing edge from each node, adding stochastic bias to the random walk. Rewards reinforce edge weights in the ECM proportionally to the difference between the expected particle mass to traverse that edge and the observed mass\n",
    "        Rewards are determined as a function of the \"surprise advantage\", i.e. how much more or less surprised the agent was then on average over its previous (relevant) experience.\n",
    "        '''\n",
    "\n",
    "        #initialize constants\n",
    "        self.num_actions = num_actions\n",
    "        self.capacity = capacity\n",
    "        self.softmax = softmax\n",
    "        self.focus = focus \n",
    "        self.kappa = kappa\n",
    "        self.intrinsic_expectations = {} if intrinsic_expectations is None else intrinsic_expectations\n",
    "        self.epsilon = epsilon\n",
    "        self.deliberation_length = deliberation_length\n",
    "        self.surprise: float = None\n",
    "        self.expectation_scale = expectation_scale\n",
    "        \n",
    "        #initialize modelling variables\n",
    "        self.t = t\n",
    "\n",
    "        #initialize ECM states\n",
    "        self.hmatrix = np.zeros((self.num_actions, self.capacity)) #weights connecting percept nodes to trace nodes\n",
    "        self.mmatrix = np.zeros((self.capacity, self.capacity)) #initialize with no connections between memory traces\n",
    "        self.trace_encoder = np.zeros((self.num_actions, self.capacity), dtype = 'bool') #boolean matrix indicating whether a percept node was encoded in a trace\n",
    "        self.action_encoder = np.ones(self.num_actions, dtype = 'bool') #boolean matrix indicated whether a percept node belongs to an action\n",
    "        self.expectations = np.zeros(self.num_actions)\n",
    "        self.beliefs = np.zeros(self.capacity) #initilize with no belief weight on any memory traces\n",
    "        self.valences = np.array([np.nan] * self.capacity) #use nan here because we will want to takes means of this array as it is filled\n",
    "        self.percept_activations = np.zeros(np.shape(self.hmatrix)[0]) #initialize with no activation of percept nodes\n",
    "        self.trace_activations = np.zeros(self.capacity) #initialize with no activation of memory traces\n",
    "        self.trace_excitations = np.zeros(self.capacity) #trace excitations represent the sensory evidence that the world is currently in a state that is effectively represented by the excited trace\n",
    "        \n",
    "\n",
    "    def deliberate(self, percept):\n",
    "        self.add_percept(percept)\n",
    "        self.surprise = self.get_surprise(percept)\n",
    "        self.excite_traces(percept)\n",
    "        self.encode_trace(percept)\n",
    "        self.activate()\n",
    "        for deliberation_step in range(self.deliberation_length):\n",
    "            self.diffuse_activation()\n",
    "        self.predict()\n",
    "        self.t = (self.t + 1) % self.capacity\n",
    "        return(self.expectations[self.action_encoder]) #return action priming\n",
    "\n",
    "    def add_percept(self, percept):\n",
    "        if len(percept) > np.shape(self.hmatrix)[0]: #if percept is longer than the first dimension of the hmatrix it means there is something new in the observation (handled by preprocessor)\n",
    "            i = np.shape(self.hmatrix)[0] #get index for new elements in ECM\n",
    "            new_elements = percept[i:len(percept)]    \n",
    "            self.hmatrix = np.append(self.hmatrix, np.zeros((len(new_elements), self.capacity)), axis = 0) #add baseline weights to connections between new percept nodes and all traces\n",
    "            self.trace_encoder = np.append(self.trace_encoder, np.zeros((len(new_elements), self.capacity), dtype = 'bool'), axis = 0) #new percept nodes have no existing connections to trace nodes\n",
    "            self.action_encoder = np.append(self.action_encoder, np.zeros(len(new_elements), dtype = 'bool')) #this ECM does not support new actions, so new percept nodes are sensory by default\n",
    "            self.expectations = np.append(self.expectations, np.array([transforms._shifted_exp(0,0, epsilon = self.epsilon) for x in range(len(new_elements))])) #sets new expectation states the same as existing sensory representations not predicted by deliberation\n",
    "            \n",
    "    def excite_traces(self, percept):\n",
    "        self.trace_excitations = np.zeros(self.capacity)\n",
    "        # each trace is excited proportionally to the probability that of the n connections it has to perceptual representations, each of those perceptual representations are excited . . .\n",
    "        # . . . if that trace effectively represents the current world state . . .\n",
    "        # . . . a logistic transfomation of connecting edge gives the probability that a sensory representation fails to excite when the world is in the state represented by the memory trace.\n",
    "        for t_index in range(self.capacity):\n",
    "            connections = [i for i in range(np.shape(self.trace_encoder)[0]) if self.trace_encoder[i,t_index]] #indexes of percept nodes with connections to memory trace\n",
    "            if np.sum(connections) > 0: #no excitation if trace has no connections (functionally this shouldn't matter, but it is nicer for interpretation)\n",
    "                #we fill the likelihoods vector\n",
    "                excitation_probs = transforms._logistic(self.hmatrix[connections,t_index], k = self.kappa)\n",
    "                likelihoods = excitation_probs**percept[connections] * ((1-excitation_probs)**(1-percept[connections])) #probabilities of Bernoulli trials with outcome equal to the excitation of connected percept nodes\n",
    "                self.trace_excitations[t_index] = np.prod(likelihoods)\n",
    "    \n",
    "    def encode_trace(self, percept):\n",
    "        self.trace_encoder[0:,self.t] = [x > 0 for x in percept] #connect all excited percepts to current trace\n",
    "        self.hmatrix[0:,self.t] = percept #h-values of edges are set to excitation of connected representation\n",
    "        self.mmatrix[self.t-1,self.t] = 1 #create forward connection from previous trace to current trace (this is a spurious but inconsequential connection for an agent's first step)\n",
    "        self.mmatrix[self.t,0:] = [0 for x in self.mmatrix[self.t,0:]] #break any forward connections from current trace (only relevant if t is greater than self.capacity)\n",
    "        self.valences[self.t-1] = self.surprise #valence is assigned to the last trace, it relfects how surprised the agent was by the outcome of the action it took in that trace\n",
    "    \n",
    "    def activate(self):\n",
    "        activation_weights = transforms._softmax(self.softmax, self.hmatrix[self.trace_encoder[0:,self.t],self.t]) #softmax function over edge weights connected to current memory trace\n",
    "        random_selection = np.random.choice(range(len(activation_weights)), p = activation_weights) #get destination of PS random walk\n",
    "        self.percept_activations = np.zeros(np.shape(self.hmatrix)[0]) #reset activations\n",
    "        #bias activation toward starting node of PS random walk\n",
    "        self.percept_activations[self.trace_encoder[0:,self.t]] = [activation_weights[i] + self.focus*(1-activation_weights[i]) if i == random_selection else activation_weights[i] * (1-self.focus) for i in range(len(activation_weights))]\n",
    "\n",
    "    def diffuse_activation(self):\n",
    "        new_percept_activations = np.zeros(np.shape(self.hmatrix)[0])\n",
    "        new_trace_activations = np.zeros(self.capacity)\n",
    "        #get diffusion from percept nodes\n",
    "        for i in range(np.shape(self.hmatrix)[0]):\n",
    "            #edge weights are the product of the the edge h-values exponent (relevance), the prior expectation of the trace to which the edge is connected (belief prior), and the excitation of the trace to which the edge is connected (sensory evidence)\n",
    "            edge_weights = self.hmatrix[i,self.trace_encoder[i,0:]] * self.beliefs[self.trace_encoder[i,0:]] * self.trace_excitations[self.trace_encoder[i,0:]]\n",
    "            if len(edge_weights) > 0: #dont diffusion activation if there are no edges (there should not be to activation to diffuse)\n",
    "                edge_probs = transforms._softmax(self.softmax, edge_weights)\n",
    "                random_selection = np.random.choice(range(len(edge_weights)), p = edge_probs) #get destination of Projective Simulations\n",
    "                diffusion_mass = _get_diffusion_mass(self.percept_activations[i], edge_probs, random_selection, self.focus)\n",
    "                new_trace_activations[self.trace_encoder[i,0:]] = new_trace_activations[self.trace_encoder[i,0:]] + diffusion_mass\n",
    "        #get diffusion from memory traces\n",
    "        for n in range(np.shape(self.hmatrix)[1]):\n",
    "            #edge weights are the product of the the edge h-values exponent (relevance), the activation of the trace to which the edge is connected (belief prior), and the excitation of the trace to which the edge is connected (sensory evidence)\n",
    "            edge_weights = np.exp(self.hmatrix[self.trace_encoder[0:,n],n])\n",
    "            if len(edge_weights) > 0: #dont diffuse activation if there are no edges (there should not be to activation to diffuse)    \n",
    "                edge_probs = transforms._softmax(self.softmax, edge_weights)\n",
    "                random_selection = np.random.choice(range(len(edge_weights)), p = edge_probs) #get destination of Projective Simulations\n",
    "                diffusion_mass = _get_diffusion_mass(self.trace_activations[n], edge_probs, random_selection, self.focus)\n",
    "                new_percept_activations[self.trace_encoder[0:,n]] = new_percept_activations[self.trace_encoder[0:,n]] + diffusion_mass\n",
    "        self.percept_activations = new_percept_activations\n",
    "        self.trace_activations = new_trace_activations\n",
    "\n",
    "    def predict(self):\n",
    "        self.beliefs = np.matmul(self.trace_activations, self.mmatrix) # because each row of the matrix has either zeros or a single 1, this just propogates attention forward. non-linear functions might be necessary for more complex mmatrix structures\n",
    "        self.expectations = np.zeros(np.shape(self.hmatrix)[0]) #hmatrix rows correspond to perceptual representations\n",
    "        for trace in range(self.capacity):\n",
    "            priming_scalers =  np.log(np.nanmean(self.valences)/self.valences)  #used to scale priming of action representations as a function of trace valence\n",
    "            priming_scalers[np.isnan(priming_scalers)] = 0 #traces without valence do not prime (including current trace)\n",
    "            #add to the expectation weight of each percept node the expectation weight of the given trace times the weight of its connection to that percept node times the priming scaler (set to one if the given percept nodes is a sensory representation)\n",
    "            self.expectations = self.expectations + self.beliefs[trace] * transforms._logistic(self.hmatrix[0:,trace], k = self.kappa) * self.trace_encoder[0:,trace] * priming_scalers[trace] ** self.action_encoder # final term sets priming to scale to 1 if the percept node is a sensory representation\n",
    "        intrinsics = np.array([intrinsic_expectations.values()[i] if i in self.intrinsic_expectations.keys() else 0 for i in range(np.shape(self.hmatrix)[0])]) #not sure whether this is nice/faster than maintaining a vector of intrinsic expectations that has zeros added whenever a new sensory representation is created?\n",
    "        self.expectations = np.array([transforms._shifted_exp(x = self.expectations[i], k = intrinsics[i], epsilon = self.epsilon) for i in range(len(self.expectations))]) # right now this has the property of slightly changing action priming. Could easily just exclude action representations from this operation, but maybe there is a more elegant solution?\n",
    "        \n",
    "    def get_surprise(self, percept):\n",
    "        not_action = np.invert(self.action_encoder) #used to exclude action representations from surprise computations\n",
    "        return np.sum(np.where(percept[not_action], -np.log2(self.expectations[not_action]), -np.log2(1-self.expectations[not_action])))\n",
    "            \n",
    "def _get_diffusion_mass(activation, edge_probs, random_selection, focus):\n",
    "    #gets the activation mass that diffuses along each edge connected to a perceptual representation. Note the different effect of the focus parameter if the edge was selected by PS random walk\n",
    "    diffusions = [None] * len(edge_probs)\n",
    "    for i in range(len(edge_probs)):\n",
    "        if i == random_selection:\n",
    "            diffusions[i] = activation * (edge_probs[i] + focus*(1-edge_probs[i]))\n",
    "        else:\n",
    "            diffusions[i] = activation * edge_probs[i] * (1 - focus)\n",
    "    return(diffusions)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574d9ef-1112-48aa-8bbe-ec80aea885ff",
   "metadata": {},
   "source": [
    "## Bayesian Memory Network\n",
    "\n",
    "The Bayesian Memory Network encodes sequences of input states (binary percept encodings) into an \"episodic-like\" memory by setting \"excitation weights\" that connect representations of perceptual elements to memory traces. Memory traces are then connected to each other by Hebbian Weights and Clip Weights. The propogation of information through the resulting graph results in predictions regarding the next percept the Bayesian Memory Network will recieve.\n",
    "\n",
    "This propogation of information can be broadly understood in three steps. \n",
    "\n",
    "First, memory trace are excited as a function of the excitation state of each element (representation) of the percept (0 or 1) and the weights of the excitation edges connecting that trace to the respective perceptual representation. Excitation weights can be understood as the probability with which the agent believes the connected percept representation will be excited, given that the connected memory trace effectively represents the agent's situation within a larger environment. Computationally, then, the excitation state of the agent's memory trace gives the likelihood of the current percept given the agent's beliefs about the situated state which that trace effectively represents.\n",
    "\n",
    "Second, a single memory trace is activated: its activation state is set to one, its other states are set to baseline, and its associated excitation weights are set according to the current percept - thus encoding the memory. This activation is then allowed to diffuse along the Hebbian Edges that connect that trace to all others, as a function of: those weights of the Hebbian edges the trace is connected to, the excitation of memory traces to which those edges lead, and the agent's prior expectation that the trace to which the edge leads will effectively represent it's current situation in the world (more on this last state in a moment). So long as the Hebbian Edge weights are all 1, activation becomes distributed amongst traces proportionally to the product of each trace's excitation state and expectation state. Thus, this process is computationally equivalent to a Bayesian update in which the set of memory traces in the BMN are assumed to respresent the true set of states from which percepts are generated and the activation state of any trace following diffusion on the graph represents the probability with the agent believes that its current situation in the world is well represented by that trace.\n",
    "\n",
    "Thirdly and finally, an expectation state is set on traces by passing the activation state along Clip Edges. Clip Edge weights are set such that activation of a memory trace will most strongly increase the expectation of the memory trace that was encoded directly after it. Thus, the expectation state of a memory trace can be understood as the probability with which the agent believes that that trace will effectively represent its upcoming situation in the broader environment. Expectation is then further passed to the perceptual representations as a function of the excitation weights connecting expected traces to the perceptual representation. Recalling that the excitation weights give the probability with which the agent believes a perceptual representation will be excited given that the agent's situation within an environment is well represented by a particular memory trace, the expectation state of a perceptual representation is computed such that it gives the probability with which the agent believes that representation will be excited by its upcoming situation in the environment, given the agent's beliefs about how probable it is that each memory trace will effectively represent that upcoming situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c1295-78f2-485f-990b-92a65d3c763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Bayesian_Memory_Network(Abstract_ECM):\n",
    "    def __init__(self,\n",
    "                 N_traces: int = 100,\n",
    "                 kappa: float = 3., #How strongly the agent discounts the similarity between two states per bit of mismatched sensory information when establishing a new belief state\n",
    "                 epsilon: float = 0.01,  # a baseline value for the priming of perceptual representations. Must be greater than 0 to prevent infinite surprise if a perceptual representation is excited that was not predicted by the agents belief state. Note this will be transormed by the logistic function, so entropy calculations are not done using precisely this number\n",
    "                 gnosticism: float = 1, #The higher this value, the more strongly the ECMs attention will move toward encoded memory traces relative to unencoded memory traces, thus its predictions will be more strongly influenced by its past experiences\n",
    "                 intrinsic_expectations: np.array = None, #each element of this 1d array scales the expectation state for a corresponding perceptual representation. Positiove values push this state toward 1, negative values toward 0.\n",
    "                 simulation_determinism: float = 5, #used as a softmax temperature when passing attention weights along clip matrix. When high, more attention from a given trace is passed as expectation to the trace(s) with the highest connection in the clip matrix\n",
    "                 t: int = 0\n",
    "                ):\n",
    "        '''\n",
    "        The Bayesian Memory Network is a graph that acts like a recurrent neural network to perform an approximate Bayesian Inference in unknown environments (where the true posterior is not known).\n",
    "        It takes a binary string (its percept) as input, and returns the probablity that each element of the next percept it recieves will be 1. Predictions are made based on the last N_traces percepts observed.\n",
    "        '''\n",
    "        super().__init__(num_actions = 0)\n",
    "        #initialize constants\n",
    "        self.N_traces = N_traces\n",
    "        self.kappa = kappa\n",
    "        self.epsilon = epsilon\n",
    "        self.gnosticism = gnosticism\n",
    "        self.intrinsic_expectations = np.array([]) if intrinsic_expectations is None else intrinsic_expectations\n",
    "        self.simulation_determinism = simulation_determinism\n",
    "        \n",
    "        #initialize modelling variables\n",
    "        self.t = t\n",
    "        self.surprise: float = None\n",
    "\n",
    "        #initialize ECM states\n",
    "        self.W = np.full(shape = (len(self.intrinsic_expectations), self.N_traces), fill_value = -self.gnosticism) #weights connecting percept nodes to trace nodes. The higher the ECMs gnosticim parameter, the more excited sesory representations will inhibit the excitation of unencoded memory traces\n",
    "        self.H = np.zeros((self.N_traces, self.N_traces)) #initialize with equal associative weights between memory traces\n",
    "        self.C = np.zeros((self.N_traces, self.N_traces)) #initialize with equal clip weights between memory traces\n",
    "        self.percept_excitations = np.zeros(np.shape(self.intrinsic_expectations)[0])\n",
    "        self.percept_expectations = np.array([]) if intrinsic_expectations is None else np.vectorize(transforms._shifted_exp)(0, self.intrinsic_expectations, self.epsilon) #sets initial percept expectations based on intrisic expectations and zero attention to associated memory traces\n",
    "        self.trace_excitations = np.zeros(self.N_traces)\n",
    "        if not np.shape(self.percept_excitations)[0] == 0:\n",
    "            self.excite_traces()\n",
    "        self.trace_expectations = np.full(shape = N_traces, fill_value = 1/self.N_traces) #trace excitations represent the sensory evidence that the world is currently in a state that is effectively represented by the excited trace\n",
    "        self.trace_activations = np.zeros(self.N_traces) #initialize with no activation of memory traces\n",
    "        \n",
    "    def deliberate(self, percept):\n",
    "        '''\n",
    "        iterates over each of the ECMs operations after recieving a new state (percept)\n",
    "        '''\n",
    "        self.percept_excitations = percept\n",
    "        self.add_percept()\n",
    "        self.excite_traces()\n",
    "        self.encode_trace()\n",
    "        self.activate()\n",
    "        self.diffuse_activation()\n",
    "        self.predict()\n",
    "        self.t = (self.t + 1) % self.N_traces\n",
    "        return [] #return action priming\n",
    "\n",
    "    def add_percept(self):\n",
    "        '''\n",
    "        Checks whether current excitation state contains new percept representations and adds any such representations to the BMNs W matrix and percept_excitations vector\n",
    "        '''\n",
    "        if np.shape(self.percept_excitations)[0] > np.shape(self.W)[0]: #if percept excitation is longer than the first dimension of the excitations weights it means there is something new in the percept\n",
    "            i = np.shape(self.W)[0] #get index for new elements in ECM\n",
    "            new_elements = self.percept_excitations[i:]    \n",
    "            self.W = np.append(self.W, np.full(shape = (len(new_elements), self.N_traces), fill_value = -self.gnosticism), axis = 0) #add baseline inhibitory weights (-1) to connections between new percept nodes and all traces\n",
    "            self.percept_expectations = np.append(self.percept_expectations, np.array([transforms._shifted_exp(0,0, epsilon = self.epsilon) for _ in range(len(new_elements))])) #sets new expectation states the same as existing sensory representations not predicted by deliberation\n",
    "            self.intrinsic_expectations = np.append(self.intrinsic_expectations, np.zeros(len(new_elements)))\n",
    "                                                    \n",
    "    def excite_traces(self):\n",
    "        '''\n",
    "        Excites the memory traces as a function of percept representation excitation, excitation weights, and the kappa parameter.\n",
    "        '''\n",
    "        percept_excitation_likelihoods = np.vectorize(transforms._logistic)(x = self.W, k = self.kappa)\n",
    "        self.trace_excitations = np.array([np.prod(percept_excitation_likelihoods[0:,j] ** self.percept_excitations * (1 - percept_excitation_likelihoods[0:,j]) ** (1 - self.percept_excitations)) for j in range(self.N_traces)])\n",
    "    \n",
    "    def encode_trace(self):\n",
    "        '''\n",
    "        update W and C as function of new percept and internal phase tracker (t)\n",
    "        '''\n",
    "        self.W[0:,self.t] = [1 if self.percept_excitations[i] == 1 else -1 for i in range(np.shape(self.W)[0])] #excitation weights to new trace are set to baseline activation (1) or inhibition (-1) based on current percept excitations\n",
    "        self.C[self.t-1,self.t] = 1 #create forward connection from previous trace to current trace (this is a spurious but inconsequential connection for an agent's first step)\n",
    "        self.C[self.t,0:] = [0] * np.shape(self.C)[1] #break any forward connections from current trace (only relevant if T is greater than N_traces)\n",
    "        \n",
    "    \n",
    "    def activate(self):\n",
    "        '''\n",
    "        removes excitation and expectation from newly encoded trace, sets its activation to 1, and removes activation from all other traces\n",
    "        '''\n",
    "        self.trace_excitations[self.t] = 0\n",
    "        self.trace_expectations[self.t] = 0\n",
    "        self.trace_activations = np.array([1 if i == self.t else 0 for i in range(self.N_traces)])\n",
    "\n",
    "    def diffuse_activation(self):\n",
    "        '''\n",
    "        Allows activation to diffusion along H matrix\n",
    "        '''\n",
    "        projection_weights = np.exp(self.H) * self.trace_expectations * self.trace_excitations\n",
    "        projection_probabilities = projection_weights * (1/(projection_weights @ np.ones((np.shape(projection_weights)[1],1)))) #divides each transition weight by the sum of transition weights in its row\n",
    "        self.trace_activations = self.trace_activations @ projection_probabilities\n",
    "\n",
    "    def predict(self):\n",
    "        '''\n",
    "        sets new expectation states\n",
    "        '''\n",
    "        simulation_weights = np.exp(self.simulation_determinism * self.C)\n",
    "        simulation_probabilities = simulation_weights * (1/(simulation_weights @ np.ones((np.shape(simulation_weights)[1],1)))) #divides each transition weight by the sum of transition weights in its row\n",
    "        self.trace_expectations = self.trace_activations @ simulation_probabilities\n",
    "        conditional_percept_probabilities = np.vectorize(transforms._logistic)(self.W, k = self.kappa)\n",
    "        self.percept_expectations = conditional_percept_probabilities @ self.trace_expectations\n",
    "        self.percept_expectations = np.vectorize(transforms._shifted_exp)(x = self.percept_expectations, k = self.intrinsic_expectations, epsilon = self.epsilon)\n",
    "\n",
    "    def get_surprise(self):\n",
    "        return np.sum(np.where(self.percept_excitations[self.num_actions:], -np.log2(self.percept_expectations[self.num_actions:]), -np.log2(1-self.percept_expectations[self.num_actions:]))) #sum for each percept representation log expecataion if excited, 1 - log expectatin if not excited\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608cf0a9-bb5e-42e1-94db-9fa5cf79dc7c",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "In this minimal example, we create a Bayesian Memory Network with ten available traces. Over fifteen time steps, we alternate whether or not a single perceptual representation is excited, and observe the BMN learning to predict this pattern. Note than after ten time steps, learning stops: the agent can only remember the last ten percepts from which it draws information to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2079479-1169-4f33-b743-90f6b0f3fbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percept expectation at time 0: [0.057]\n",
      "percept expectation at time 1: [0.299]\n",
      "percept expectation at time 2: [0.319]\n",
      "percept expectation at time 3: [0.109]\n",
      "percept expectation at time 4: [0.863]\n",
      "percept expectation at time 5: [0.077]\n",
      "percept expectation at time 6: [0.899]\n",
      "percept expectation at time 7: [0.081]\n",
      "percept expectation at time 8: [0.912]\n",
      "percept expectation at time 9: [0.087]\n",
      "percept expectation at time 10: [0.923]\n",
      "percept expectation at time 11: [0.087]\n",
      "percept expectation at time 12: [0.923]\n",
      "percept expectation at time 13: [0.087]\n",
      "percept expectation at time 14: [0.923]\n"
     ]
    }
   ],
   "source": [
    "BMN = Bayesian_Memory_Network(N_traces = 10)\n",
    "for t in range(15):\n",
    "    BMN.deliberate(np.array([t % 2]))\n",
    "    print(\"percept expectation at time \" + str(t) + \": \" + str(np.round(BMN.percept_expectations, decimals = 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aed943e-ccc2-469a-91d5-b908ca94a54a",
   "metadata": {},
   "source": [
    "## Active Inference Memory Network\n",
    "\n",
    "The Active Inference Memory Network builds upon the Bayesian Memory Network by allowing a set of perceptual represenations to correspond to actions and by modulating the expectation state of those action representations as a function of a \"surprise\" value which is now encoded in memory traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e467734-70d5-431b-9f69-e935c09e35d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class Active_Inference_Memory_Network(Bayesian_Memory_Network):\n",
    "    def __init__(self,\n",
    "                 num_actions: int,\n",
    "                 N_traces: int = 100,\n",
    "                 kappa: float = 3., #How strongly the agent discounts the similarity between two states per bit of mismatched sensory information when establishing a new belief state\n",
    "                 epsilon: float = 0.01,  # a baseline value for the priming of perceptual representations. Must be greater than 0 to prevent infinite surprise if a perceptual representation is excited that was not predicted by the agents belief state. Note this will be transormed by the logistic function, so entropy calculations are not done using precisely this number\n",
    "                 gnosticism: float = 1, #The higher this value, the more strongly the ECMs attention will move toward encoded memory traces relative to unencoded memory traces, thus its predictions will be more strongly influenced by its past experiences\n",
    "                 intrinsic_sensory_expectations: np.array = None, #each element of this 1d array scales the expectation state for a corresponding SENSORY representation (SHOULD NOT INCLUDE ACTION REPRESENTATIONS). Upon initiation, AIMN constructs an intrinsic_expectations variable from this array and num_actions\n",
    "                 simulation_determinism: float = 5, #used as a softmax temperature when passing attention weights along clip matrix. When high, more attention from a given trace is passed as expectation to the trace(s) with the highest connection in the clip matrix\n",
    "                 t: int = 0,\n",
    "                 memory_valences: float = None\n",
    "                ):\n",
    "        self.num_actions = num_actions\n",
    "        self.memory_valences = np.array([np.nan] * N_traces) if memory_valences is None else memory_valences\n",
    "        if intrinsic_sensory_expectations is None:\n",
    "            intrinsic_expectations = np.zeros(num_actions)\n",
    "        else:\n",
    "            intrinsic_expectations = np.append(np.zeros(num_actions), intrinsic_sensory_expectations)\n",
    "        \n",
    "        super().__init__(N_traces = N_traces, kappa = kappa, epsilon = epsilon, gnosticism = gnosticism, \n",
    "                         intrinsic_expectations = intrinsic_expectations, simulation_determinism = simulation_determinism, t = t)\n",
    "\n",
    "    \n",
    "\n",
    "    def encode_trace(self):\n",
    "        super().encode_trace()\n",
    "        self.memory_valences[self.t - 1] = self.get_surprise()\n",
    "\n",
    "    def predict(self):\n",
    "        '''\n",
    "        sets new expectation states\n",
    "        '''\n",
    "        #first four line the same as Bayesian Memory Network~~~~~\n",
    "        simulation_weights = np.exp(self.simulation_determinism * self.C)\n",
    "        simulation_probabilities = simulation_weights * (1/(simulation_weights @ np.ones((np.shape(simulation_weights)[1],1)))) #divides each transition weight by the sum of transition weights in its row\n",
    "        self.trace_expectations = self.trace_activations @ simulation_probabilities\n",
    "        conditional_percept_probabilities = np.vectorize(transforms._logistic)(self.W, k = self.kappa)\n",
    "        #~~~~~~\n",
    "        #Modify predictions to 'prime' action representations\n",
    "        priming = np.log(np.nanmean(self.memory_valences)/self.memory_valences)  #used to scale priming of action representations as a function of trace valence\n",
    "        priming[np.isnan(priming)] = 0 #traces without valence do not prime (including current trace)\n",
    "        for i in range(self.num_actions):\n",
    "            conditional_percept_probabilities[i,0:] = conditional_percept_probabilities[i,0:] * priming\n",
    "        self.percept_expectations = conditional_percept_probabilities @ self.trace_expectations\n",
    "        #adjust expectation based on intrinsic expectations\n",
    "        self.percept_expectations = np.vectorize(transforms._shifted_exp)(x = self.percept_expectations, k = self.intrinsic_expectations, epsilon = self.epsilon)\n",
    "        \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faffc472-4ca5-4a17-ae5b-31dee1c28ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0590074  0.94519832 0.58810569 0.93326371]\n",
      "[0.00595979 0.52178372 0.0822386  0.90402525]\n",
      "[0.14611547 0.38694216 0.54577185 0.70317034]\n",
      "[0.08655953 0.02921709 0.08034339 0.70134384]\n",
      "[0.02097371 0.1109066  0.1646673  0.74118359]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.03691235, 0.56865592, 0.11503003, 0.93436008])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_AIM = Active_Inference_Memory_Network(num_actions = 2, intrinsic_sensory_expectations = np.array([0,2]))\n",
    "test_AIM.deliberate(np.array([1,0,1,0]))\n",
    "test_AIM.deliberate(np.array([1,0,0,0]))\n",
    "test_AIM.deliberate(np.array([1,0,1,0]))\n",
    "test_AIM.deliberate(np.array([1,0,0,0]))\n",
    "test_AIM.deliberate(np.array([0,1,1,0]))\n",
    "test_AIM.deliberate(np.array([0,1,0,1]))\n",
    "test_AIM.deliberate(np.array([0,1,1,1]))\n",
    "test_AIM.deliberate(np.array([0,1,0,1]))\n",
    "print(test_AIM.percept_expectations)\n",
    "test_AIM.deliberate(np.array([1,0,1,1]))\n",
    "print(test_AIM.percept_expectations)\n",
    "test_AIM.deliberate(np.array([1,0,0,0]))\n",
    "print(test_AIM.percept_expectations)\n",
    "test_AIM.deliberate(np.array([1,0,1,0]))\n",
    "print(test_AIM.percept_expectations)\n",
    "test_AIM.deliberate(np.array([0,1,0,0]))\n",
    "print(test_AIM.percept_expectations)\n",
    "test_AIM.deliberate(np.array([0,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59a3c8-bed2-49c6-ae40-3d54c69550f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.74310639, 5.45182924, 1.77754646, 2.43905815, 0.67528552,\n",
       "       3.78738387, 0.55285169, 0.86549595, 3.50501032, 2.62592292,\n",
       "       1.86427545,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan, 7.76440401])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_AIM.memory_valences       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2f7b7-e76e-4d04-b400-cd9c1cb3f205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 2.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_AIM.intrinsic_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e993c-3c81-4fbd-accb-066982eda179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104705378870178"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms._shifted_exp(0.5, 2, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f297856-8c4e-48ad-aaa6-e42f4886acb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
